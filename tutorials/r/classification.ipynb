{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Classification Example Using Exasol and R\n",
    "================\n",
    "\n",
    "-   [Train locally, predict in Exasol](#train-locally-predict-in-exasol)\n",
    "    -   [Send model to BucketFS](#send-model-to-bucketfs)\n",
    "    -   [Send data to Exasol](#send-data-to-exasol)\n",
    "    -   [Make prediction using UDF](#make-prediction-using-udf)\n",
    "-   [Train and predict in Exasol](#train-and-predict-in-exasol)\n",
    "-   [Bonus: Predict via UDF in SQL](#bonus-predict-via-udf-in-sql)\n",
    "\n",
    "The following demo illustrates how to use R and Exasol, both as standalone tools and combined, to run a machine learning algorithm such as Random Forests (RF) on some data. A central feature is the use of Exasol R package and especially Exasol's user defined functions (UDFs).\n",
    "\n",
    "> UDF scripts provide you with the ability to program your own analyses, processing or generation functions and execute them in parallel inside Exasol's high performance cluster. See [Exasol User Manual](https://www.exasol.com/support/secure/attachment/70209/EXASOL_User_Manual-6.1.0-en.pdf) for more information.\n",
    "\n",
    "UDF scripts play a pivotal role and provide the user with a flexible interface for implementing every requirement by integrating Java, Lua, Python and R language to Exasol native environment. However, the Exasol database environment is not the only place we can make use of UDFs. Exasol R package also allows for the use of UDFs via `exa.createScript()` function which deploys R code dynamically from any R environment into Exasol database in parallel. See `?exa.createScript` for more information.\n",
    "\n",
    "The typical (supervised) learning process starts with training a model on some sample training data. Then, the trained model can be used to make predictions on separate (unseen) test data. The data in our case consists of housing data from the [Boston Housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/) dataset. This will be a regression exercise since the response variable we are trying to predict is a continuous one, the median value of housing `medv`.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "-   [R programming language](https://www.r-project.org/)\n",
    "-   [RStudio](https://www.rstudio.com/)\n",
    "-   [Exasol R package](https://github.com/EXASOL/r-exasol)\n",
    "-   [Exasol Community Edition](https://www.exasol.com/portal/display/DOWNLOAD/Free+Trial)\n",
    "-   SQL development tool\n",
    "-   ODBC and [Exasol ODBC Driver](https://www.exasol.com/portal/display/DOWNLOAD/6.1)\n",
    "-   [BucketFS Explorer](https://github.com/EXASOL/bucketfs-explorer)\n",
    "\n",
    "Conventionally, one would load the data from a local machine into R, RStudio or a Jupyter Server. Then, you would run the analysis by training the model, evaluating and making predictions in such environment. However, we want to make use of Exasol database and this opens up the possibility of two additional scenarios:\n",
    "\n",
    "-   Train locally and make predictions in Exasol\n",
    "-   Train and make predictions in Exasol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "=====\n",
    "\n",
    "First we need to install, load and setup the r-exasol packages. You need devtools to install r-exasol, because we are currently not able to release it in CRAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install devtools if needed\n",
    "install.packages(\"devtools\",repos = \"http://cran.us.r-project.org\")\n",
    "\n",
    "# Install package using devtools\n",
    "devtools::install_github(\"EXASOL/r-exasol\")\n",
    "library(exasol)   # Exasol package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the r-exasol package, we need to load all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"RODBC\",repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"ggplot2\",repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"randomForest\",repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"RCurl\",repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"tictoc\",repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"mlbench\",repos = \"http://cran.us.r-project.org\")\n",
    "\n",
    "# load necassrary libraries for local training\n",
    "library(RODBC)           # ODBC connectivity\n",
    "library(ggplot2)         # Plotting\n",
    "library(randomForest)    # Random forests for regression and classification\n",
    "library(RCurl)           # HTTP communication\n",
    "library(tictoc)          # Timing Functions\n",
    "library(mlbench)         # Library containing the Boston Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of exasol defines necessary information for connecting to Exasol and the BucketFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXASOL_HOST = \"10.10.10.11:8888\"\n",
    "EXASOL_USER = \"sys\"\n",
    "EXASOL_PASSWORD = \"exasol\"\n",
    "EXASOL_BUCKETFS_HOST = \"10.10.10.11:6583\"\n",
    "EXASOL_BUCKETFS_USER = \"w\"\n",
    "EXASOL_BUCKETFS_PASSWORD = \"write\"\n",
    "EXASOL_BUCKETFS_USE_HTTPS = FALSE\n",
    "EXASOL_BUCKETFS_SERVICE = \"bfsdefault\"\n",
    "EXASOL_BUCKETFS_BUCKET = \"default\"\n",
    "MODEL_NAME= \"rf_model\"\n",
    "EXASOL_BUCKETFS_URL_PREFIX = if (EXASOL_BUCKETFS_USE_HTTPS) {\"https://\" } else {\"http://\"}\n",
    "EXASOL_BUCKETFS_PROTOCOL <- if(EXASOL_BUCKETFS_USE_HTTPS) \"https\" else \"http\"\n",
    "EXASOL_BUCKETFS_PATH = sprintf(\"/%s/%s\",EXASOL_BUCKETFS_SERVICE,EXASOL_BUCKETFS_BUCKET)\n",
    "UDF_ENV=list(EXASOL_BUCKETFS_PROTOCOL=EXASOL_BUCKETFS_PROTOCOL,\n",
    "             EXASOL_BUCKETFS_HOST=EXASOL_BUCKETFS_HOST,\n",
    "             EXASOL_BUCKETFS_USER=EXASOL_BUCKETFS_USER,\n",
    "             EXASOL_BUCKETFS_PASSWORD=EXASOL_BUCKETFS_PASSWORD,\n",
    "             EXASOL_BUCKETFS_PATH=EXASOL_BUCKETFS_PATH,\n",
    "             EXASOL_BUCKETFS_BUCKET=EXASOL_BUCKETFS_BUCKET,\n",
    "             EXASOL_BUCKETFS_SERVICE=EXASOL_BUCKETFS_SERVICE,\n",
    "             MODEL_NAME=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train locally, predict in Exasol\n",
    "================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start by loading the data in R. The Boston Housing dataset is available through the `mlbench` package which we installed during the setup. This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms.\n",
    "After loading the data in our environment we will make a split for training and testing sets. This can be done in many ways but one way is to randomly generate indices that will subset rows from the main set. The ratio of the split is arbitrary and depends on data and application at hand. In this simple case will hold roughly 75% of the data for training and the other 25% for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data(\"BostonHousing\")\n",
    "\n",
    "# Generate random indices (75% of the sample size)\n",
    "set.seed(42)\n",
    "indices <- sample(nrow(BostonHousing),size=floor(nrow(BostonHousing) * 0.75))\n",
    "\n",
    "# Add a dummy variable with 2 levels \"Train\" and \"Test\"\n",
    "BostonHousing$split = factor(NA, levels = c(\"Train\", \"Test\"))\n",
    "\n",
    "# Assign predefined rows respectively to \"Train\" and \"Test\" subsets\n",
    "BostonHousing$split[indices]  = \"Train\"\n",
    "BostonHousing$split[-indices] = \"Test\"\n",
    "\n",
    "# Add id variable\n",
    "BostonHousing$id = seq(1:nrow(BostonHousing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a basic random forest model on our data and see which variables contribute the most to predicting the median house value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "# Run model (note that we filter only for the training data (split==\"Train\"))\n",
    "rf_model = randomForest(medv ~ .-split -id,\n",
    "                        data = BostonHousing[BostonHousing$split==\"Train\",],\n",
    "                        importance = TRUE)\n",
    "\n",
    "# See which variables are important in predicting house prices\n",
    "varImpPlot(rf_model)\n",
    "# rm    - number of rooms per house\n",
    "# lstat - % lower status of the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send model to BucketFS\n",
    "----------------------\n",
    "\n",
    "UDF scripts are executed in parallel on the Exasol cluster and in our case for the prediction, such a script needs to have access to the model we just trained. While it is possible to use any file service, when considering performance it is more efficient to have a storage space in the local cluster nodes. Keep in mind that the Exasol database cluster stores only tables and we cannot simply upload our model in there. The *Exasol BucketFS* file system has been created to handle such needs.\n",
    "\n",
    "> The Exasol BucketFS file system has been developed for such use cases, where data should be stored synchronously and replicated across the cluster... this concept can be used to extend script languages and even to install completely new script languages on the Exasol cluster. [Exasol User Manual](https://docs.exasol.com/database_concepts/udf_scripts/synchronous_cfs_bucketfs.htm)\n",
    "\n",
    "Files can be sent and retrieved from BucketFS in the following ways:\n",
    "\n",
    "-   Using packages that allow HTTP communication in R (`httr` or `RCurl`)\n",
    "-   [BucketFS Explorer](https://github.com/EXASOL/bucketfs-explorer) (drag and drop tool provided by Exasol which requires a connection to ExaOperation and as this currently not useable with the [Exasol Docker-DB](https://github.com/exasol/docker-db))\n",
    "-   Using `curl` commands (will not be shown here)\n",
    "\n",
    "With the first method we will use the `RCurl` package. It is important to note that the model which lives in our R environment now has to be serialized (converted into raw text). When we want to retrieve it we can unserialize it and return it to its original data type. See `?serialize` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define options for the authentication\n",
    "curl_opts = curlOptions(userpwd  = sprintf(\"%s:%s\",EXASOL_BUCKETFS_USER,EXASOL_BUCKETFS_PASSWORD),\n",
    "                        verbose  = FALSE,\n",
    "                        httpauth = AUTH_BASIC)\n",
    "\n",
    "url = sprintf(\"%s://%s/%s/%s\",EXASOL_BUCKETFS_PROTOCOL,EXASOL_BUCKETFS_HOST,EXASOL_BUCKETFS_BUCKET,MODEL_NAME)\n",
    "print(sprintf(\"Upload model to %s\",url))\n",
    "# Transfer model to the bucket\n",
    "res=httpPUT(\n",
    "  # EXABucket URL\n",
    "  url = url,\n",
    "  # It is important to serialize the model\n",
    "  content = serialize(rf_model, ascii = FALSE, connection = NULL),\n",
    "  # EXABucket: authenticate\n",
    "  curl = getCurlHandle(.opts = curl_opts)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In cases when the size of youe model becomes an issue, it is worth checking the [Strip](https://cran.r-project.org/web/packages/strip/strip.pdf) package which allows you to reduce the memory footprint of your models.\n",
    "\n",
    "With the following code, we can check if the model was transfered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define options for the authentication\n",
    "curl_opts = curlOptions(userpwd  = sprintf(\"%s:%s\",EXASOL_BUCKETFS_USER,EXASOL_BUCKETFS_PASSWORD),\n",
    "                        verbose  = FALSE,\n",
    "                        httpauth = AUTH_BASIC)\n",
    "url = sprintf(\"%s://%s/%s\",EXASOL_BUCKETFS_PROTOCOL,EXASOL_BUCKETFS_HOST,EXASOL_BUCKETFS_BUCKET)\n",
    "print(sprintf(\"Fetch url %s\",url))\n",
    "# Transfer model to the bucket\n",
    "get = getURL(\n",
    "  # EXABucket URL\n",
    "  url = url,\n",
    "  # EXABucket: authenticate\n",
    "  curl = getCurlHandle(.opts = curl_opts)\n",
    ")\n",
    "files <- strsplit(get[[1]], \"\\n\")\n",
    "res <- lapply(files, function(ch) ch==MODEL_NAME)\n",
    "if(any(unlist(res, use.names=FALSE))){\n",
    "    print(\"Found model file.\")\n",
    "}else{\n",
    "    print(\"Did not found model file.\")\n",
    "    print(\"Following files are in the Bucket:\")\n",
    "    print(files)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send data to Exasol\n",
    "-------------------\n",
    "\n",
    "In order to run the prediction in Exasol we need to transfer the data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection with the EXASOL database\n",
    "exaconn <- dbConnect(\n",
    "    drv     = \"exa\",                  # EXAdriver object\n",
    "    exahost = EXASOL_HOST,  # IP of database cluster\n",
    "    uid     = EXASOL_USER,                  # Username\n",
    "    pwd     = EXASOL_PASSWORD)               # Password\n",
    "\n",
    "# Create database schema (if it does not yet exist) with the name r_demo\n",
    "# (This also opens it, i.e. makes it the default container for all subsequent steps below)\n",
    "odbcQuery(exaconn, \"CREATE SCHEMA IF NOT EXISTS r_demo\")\n",
    "\n",
    "# If the schema already existed, we need to open it to make it the default container for all subsequent steps below\n",
    "odbcQuery(exaconn, \"OPEN SCHEMA r_demo\")\n",
    "\n",
    "# Create an empty table in EXASOL with the name boston_housing\n",
    "odbcQuery(exaconn,\n",
    "    \"CREATE OR REPLACE TABLE boston_housing(\n",
    "         crim    DOUBLE,\n",
    "         zn      DOUBLE,\n",
    "         indus   DOUBLE,\n",
    "         chas    VARCHAR(10),\n",
    "         nox     DOUBLE,\n",
    "         rm      DOUBLE,\n",
    "         age     DOUBLE,\n",
    "         dis     DOUBLE,\n",
    "         rad     DOUBLE,\n",
    "         tax     DOUBLE,\n",
    "         ptratio DOUBLE,\n",
    "         b       DOUBLE,\n",
    "         lstat   DOUBLE,\n",
    "         medv    DOUBLE,\n",
    "         split   VARCHAR(10),\n",
    "         id      INT\n",
    "     )\")\n",
    "\n",
    "# Write the train data into Exasol\n",
    "exa.writeData(exaconn, data = BostonHousing, tableName = \"boston_housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can retrieve the data from the database and examining it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection with the EXASOL database\n",
    "exaconn <- dbConnect(\n",
    "    drv     = \"exa\",                         # EXAdriver object\n",
    "    exahost = EXASOL_HOST,                   # IP of database cluster\n",
    "    uid     = EXASOL_USER,                   # Username\n",
    "    pwd     = EXASOL_PASSWORD)               # Password\n",
    "\n",
    "# If the schema already existed, we need to open it to make it the default container for all subsequent steps below\n",
    "odbcQuery(exaconn, \"OPEN SCHEMA r_demo\")\n",
    "dbGetQuery(exaconn, \"select * from boston_housing limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction using UDFs\n",
    "--------------------------\n",
    "\n",
    "We are now ready to use the algorithm which is in the BucketFS to run a prediction on the data which is in Exasol. For this we will use a UDF and in R this is achieved by the `exa.createScript` function. The `exa.createScript` function create from a local R function a UDF within Exasol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection with the EXASOL database\n",
    "exaconn <- dbConnect(\n",
    "    drv     = \"exa\",                  # EXAdriver object\n",
    "    exahost = EXASOL_HOST,            # IP of database cluster\n",
    "    uid     = EXASOL_USER,            # Username\n",
    "    pwd     = EXASOL_PASSWORD)        # Password\n",
    "PredictInExasol1 <- exa.createScript(\n",
    "  exaconn,\n",
    "  \"r_demo.dt_predict1\",\n",
    "  function(data) {\n",
    "\n",
    "    # Load the required packages\n",
    "    require(RCurl)\n",
    "    require(randomForest)\n",
    "\n",
    "    # Set options for retrieving model from bucket\n",
    "    curl_opts = curlOptions(userpwd = sprintf(\"%s:%s\",env$EXASOL_BUCKETFS_USER,env$EXASOL_BUCKETFS_PASSWORD),\n",
    "                            verbose = TRUE,\n",
    "                            httpauth=AUTH_BASIC)\n",
    "\n",
    "    # Loading the model from the bucket (note that is unserialized)\n",
    "    rf_model = unserialize(httpGET(url  = sprintf(\"%s://%s/%s/%s\",\n",
    "                                                  env$EXASOL_BUCKETFS_PROTOCOL,env$EXASOL_BUCKETFS_HOST,\n",
    "                                                  env$EXASOL_BUCKETFS_BUCKET,env$MODEL_NAME),\n",
    "                                   curl = getCurlHandle(.opts = curl_opts)))\n",
    "\n",
    "      \n",
    "    # Load data in chuks of 1000 rows at a time (very useful knob with big data!)\n",
    "    repeat {\n",
    "      if (!data$next_row(1000))\n",
    "        break\n",
    "\n",
    "      # put data in a data.frame\n",
    "      df <- data.frame(\n",
    "              id       = data$id,\n",
    "              crim     = data$crim,\n",
    "              zn       = data$zn,\n",
    "              indus    = data$indus,\n",
    "              chas     = data$chas,\n",
    "              nox      = data$nox,\n",
    "              rm       = data$rm,\n",
    "              age      = data$age,\n",
    "              dis      = data$dis,\n",
    "              rad      = data$rad,\n",
    "              tax      = data$tax,\n",
    "              ptratio  = data$ptratio,\n",
    "              b        = data$b,\n",
    "              lstat    = data$lstat,\n",
    "              medv     = data$medv,\n",
    "              split    = data$split\n",
    "            )\n",
    "\n",
    "      # Use the loaded model to make the prediction\n",
    "      prediction <- predict(rf_model, newdata = df)\n",
    "    }\n",
    "    # Return of the forecast\n",
    "    data$emit(df$id, df$medv, prediction)\n",
    "  },\n",
    "  env = UDF_ENV,\n",
    "  # Input arguments\n",
    "  inArgs  = c(\"id         INT\",\n",
    "              \"crim       DOUBLE\",\n",
    "              \"zn         DOUBLE\",\n",
    "              \"indus      DOUBLE\",\n",
    "              \"chas       VARCHAR(10)\",\n",
    "              \"nox        DOUBLE\",\n",
    "              \"rm         DOUBLE\",\n",
    "              \"age        DOUBLE\",\n",
    "              \"dis        DOUBLE\",\n",
    "              \"rad        DOUBLE\",\n",
    "              \"tax        DOUBLE\",\n",
    "              \"ptratio    DOUBLE\",\n",
    "              \"b          DOUBLE\",\n",
    "              \"lstat      DOUBLE\",\n",
    "              \"medv       DOUBLE\",\n",
    "              \"split      VARCHAR(10)\"),\n",
    "\n",
    "  # Output arguments\n",
    "  outArgs = c(\"id         INT\",\n",
    "              \"RealValue  DOUBLE\",\n",
    "              \"Prediction DOUBLE\")\n",
    ")\n",
    "tic(\"PredictInExasol1\")\n",
    "# Create a table with the real values and predicted ones\n",
    "# Note that the prediction is done in test data using 'where' argument\n",
    "prediction_output = PredictInExasol1(\"id\",\"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\",\n",
    "                                     \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\", \"split\",\n",
    "                                     table = \"r_demo.boston_housing\",\n",
    "                                     groupBy = \"iproc(),mod(rownum,5)\",\n",
    "                                     where = \"split = 'Test'\")\n",
    "toc()\n",
    "# Check the root mean squared error (RMSE)\n",
    "RMSE = sqrt(mean((prediction_output$PREDICTION - prediction_output$REALVALUE)^2))\n",
    "print(RMSE)\n",
    "# Should be 3.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parallelize the execution for of the prediction with the group by clause. The function iproc() returns the current Exasol Node Id for the current row and the function mod(rownum,5) splits the rows into 5 partition. This means, we encourage the database to start on each 5 UDF instances per node and encourage data locality. Note: Under load high load, the number of instances might be lower, but in normal circumstances the database provides the specified parallelization.\n",
    "\n",
    "After the prediction finished,We can also plot our predicted values and see the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions against real values\n",
    "library(ggplot2)\n",
    "\n",
    "plot_predictions = ggplot(prediction_output, aes(ID)) +\n",
    "                    geom_line(aes(y = PREDICTION, colour = \"Prediction\")) +\n",
    "                    geom_line(aes(y = REALVALUE, colour = \"True Value\")) +\n",
    "                    xlab(\"\") +\n",
    "                    ylab(\"Results\") +\n",
    "                    ggtitle(\"Predicted vs Real values\")\n",
    "                    theme(legend.title=element_blank())\n",
    "\n",
    "plot(plot_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and predict in Exasol\n",
    "===========================\n",
    "\n",
    "We will now make use of the UDFs to train our model within the Exasol cluster. Inside the UDF we read the data from the database into a `data.frame` object which we use to train the model. We then send this model to BucketFS for future usage and return some model information (variable importance in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainInExasol2 <- exa.createScript(\n",
    "  exaconn,\n",
    "  \"r_demo.dt_train2\",\n",
    "  function(data) {\n",
    "\n",
    "    # Load the required packages\n",
    "    library(randomForest)\n",
    "    library(RCurl)\n",
    "\n",
    "    # Load the data into the UDF. \n",
    "    # CAUTION: UDFs have only a limited ammount of main memory\n",
    "    # Unfortunatly, most of the R packages for Machine Learning \n",
    "    # require the whole training set in memory.\n",
    "    # We are going to show in other examples some libraries which\n",
    "    # work with chunks of data\n",
    "    if (!data$next_row(NA))\n",
    "        break\n",
    "\n",
    "    # Transform into data frame\n",
    "    df <- data.frame(\n",
    "          id       = data$id,\n",
    "          crim     = data$crim,\n",
    "          zn       = data$zn,\n",
    "          indus    = data$indus,\n",
    "          chas     = data$chas,\n",
    "          nox      = data$nox,\n",
    "          rm       = data$rm,\n",
    "          age      = data$age,\n",
    "          dis      = data$dis,\n",
    "          rad      = data$rad,\n",
    "          tax      = data$tax,\n",
    "          ptratio  = data$ptratio,\n",
    "          b        = data$b,\n",
    "          lstat    = data$lstat,\n",
    "          medv     = data$medv,\n",
    "          split    = data$split\n",
    "        )\n",
    "\n",
    "    # Run random forest\n",
    "    set.seed(42)\n",
    "    rf_model2 <- randomForest(medv ~ .-id -split,\n",
    "                              data = df[df$split==\"Train\",],\n",
    "                              importance = TRUE)\n",
    "\n",
    "    curl_opts = curlOptions(userpwd = sprintf(\"%s:%s\",env$EXASOL_BUCKETFS_USER,env$EXASOL_BUCKETFS_PASSWORD),\n",
    "                            verbose = TRUE,\n",
    "                            httpauth=AUTH_BASIC)\n",
    "    RCurl:::httpPUT(\n",
    "      url     = sprintf(\"%s://%s/%s/%s\",\n",
    "                      env$EXASOL_BUCKETFS_PROTOCOL,env$EXASOL_BUCKETFS_HOST,\n",
    "                      env$EXASOL_BUCKETFS_BUCKET,env$MODEL_NAME),\n",
    "      content = serialize(rf_model2, ascii = FALSE, connection = NULL),\n",
    "      curl    = getCurlHandle(.opts = curl_opts)\n",
    "    )\n",
    "\n",
    "    # Return the line number\n",
    "    data$emit(rownames(rf_model2$importance),\n",
    "              unname(rf_model2$importance[,1]),\n",
    "              unname(rf_model2$importance[,2]))\n",
    "  },\n",
    "  env=UDF_ENV,\n",
    "  # Input arguments\n",
    "  inArgs  = c(\"id         INT\",\n",
    "              \"crim       DOUBLE\",\n",
    "              \"zn         DOUBLE\",\n",
    "              \"indus      DOUBLE\",\n",
    "              \"chas       VARCHAR(10)\",\n",
    "              \"nox        DOUBLE\",\n",
    "              \"rm         DOUBLE\",\n",
    "              \"age        DOUBLE\",\n",
    "              \"dis        DOUBLE\",\n",
    "              \"rad        DOUBLE\",\n",
    "              \"tax        DOUBLE\",\n",
    "              \"ptratio    DOUBLE\",\n",
    "              \"b          DOUBLE\",\n",
    "              \"lstat      DOUBLE\",\n",
    "              \"medv       DOUBLE\",\n",
    "              \"split      VARCHAR(10)\"),\n",
    "\n",
    "  # Output arguments\n",
    "  outArgs = c(\"Variable   CHAR(20)\",\n",
    "              \"MSE        DOUBLE\",\n",
    "              \"NodePurity DOUBLE\")\n",
    ")\n",
    "\n",
    "tic(\"TrainInExasol2\")\n",
    "#Call of the function. The return is stored in an object\n",
    "variable_importance = TrainInExasol2(\"id\",\"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\",\n",
    "                                     \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\", \"split\",\n",
    "                                     table = \"r_demo.boston_housing\",\n",
    "                                     where = \"split = 'Train'\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We don't use a group by clause here, because the used random forrest library needs the whole dataset in the memory of R environment inside of the UDF.\n",
    "\n",
    "Now that we have the model, `rf_model2`, stored in BucketFS we will use it to make predictions on our test data which lives in the Exasol database. The testing procedure is the same as in the scenario above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do we need the second definition? probably not\n",
    "# TODO get bucketfs info from connection\n",
    "# TODO automate tranformation into dataframe \n",
    "PredictInExasol2 <- exa.createScript(\n",
    "  exaconn,\n",
    "  \"r_demo.dt_predict2\",\n",
    "  function(data) {\n",
    "\n",
    "    # Load the required packages\n",
    "    require(RCurl)\n",
    "    require(randomForest)\n",
    "\n",
    "    # Set options for retrieving model from bucket\n",
    "    curl_opts = curlOptions(userpwd = sprintf(\"%s:%s\",env$EXASOL_BUCKETFS_USER,env$EXASOL_BUCKETFS_PASSWORD),\n",
    "                            verbose = TRUE,\n",
    "                            httpauth=AUTH_BASIC)\n",
    "\n",
    "    # Loading the model from the bucket (note that is unserialized)\n",
    "    rf_model2 = unserialize(httpGET(url  = sprintf(\"%s://%s/%s/%s\",\n",
    "                                                  env$EXASOL_BUCKETFS_PROTOCOL,env$EXASOL_BUCKETFS_HOST,\n",
    "                                                  env$EXASOL_BUCKETFS_BUCKET,env$MODEL_NAME),\n",
    "                                   curl = getCurlHandle(.opts = curl_opts)))\n",
    "\n",
    "    # Load data in chuks of 1000 rows at a time\n",
    "    repeat{\n",
    "        if (!data$next_row(1000))\n",
    "            break\n",
    "\n",
    "      # Load the data into a data.frame\n",
    "      df <- data.frame(id       = data$id,\n",
    "                       crim     = data$crim,\n",
    "                       zn       = data$zn,\n",
    "                       indus    = data$indus,\n",
    "                       chas     = data$chas,\n",
    "                       nox      = data$nox,\n",
    "                       rm       = data$rm,\n",
    "                       age      = data$age,\n",
    "                       dis      = data$dis,\n",
    "                       rad      = data$rad,\n",
    "                       tax      = data$tax,\n",
    "                       ptratio  = data$ptratio,\n",
    "                       b        = data$b,\n",
    "                       lstat    = data$lstat,\n",
    "                       medv     = data$medv,\n",
    "                       split    = data$split)\n",
    "\n",
    "\n",
    "      # Use the loaded model to make the prediction\n",
    "      prediction <- predict(rf_model2, newdata = df)\n",
    "    }\n",
    "      \n",
    "    # Return the forecast\n",
    "    data$emit(df$id, df$medv, prediction)\n",
    "  },\n",
    "  env=UDF_ENV,\n",
    "  # iInput arguments\n",
    "  inArgs  = c(\"id         INT\",\n",
    "              \"crim       DOUBLE\",\n",
    "              \"zn         DOUBLE\",\n",
    "              \"indus      DOUBLE\",\n",
    "              \"chas       VARCHAR(10)\",\n",
    "              \"nox        DOUBLE\",\n",
    "              \"rm         DOUBLE\",\n",
    "              \"age        DOUBLE\",\n",
    "              \"dis        DOUBLE\",\n",
    "              \"rad        DOUBLE\",\n",
    "              \"tax        DOUBLE\",\n",
    "              \"ptratio    DOUBLE\",\n",
    "              \"b          DOUBLE\",\n",
    "              \"lstat      DOUBLE\",\n",
    "              \"medv       DOUBLE\",\n",
    "              \"split      VARCHAR(10)\"),\n",
    "\n",
    "  # Output arguments\n",
    "  outArgs = c(\"id         INT\",\n",
    "              \"RealValue  DOUBLE\",\n",
    "              \"Prediction DOUBLE\")\n",
    ")\n",
    "\n",
    "tic(\"PredictInExasol2\")\n",
    "# Create a table with the real values and predicted ones\n",
    "prediction_output2 = PredictInExasol2(\"id\",\"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\",\n",
    "                                      \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\", \"split\",\n",
    "                                      table = \"r_demo.boston_housing\",\n",
    "                                      groupBy = \"iproc(),mod(rownum,5)\",\n",
    "                                      where = \"split = 'Test'\")\n",
    "toc()\n",
    "\n",
    "# Check the root mean squared error (RMSE)\n",
    "RMSE = sqrt(mean((prediction_output2$PREDICTION - prediction_output2$REALVALUE)^2))\n",
    "# 3.35, similar to the one above\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Predict via UDF in SQL\n",
    "=============================\n",
    "\n",
    "We can run the same exact prediction model from Exasol native environment in the SQL development tool. The model can be deployed using a UDF which dynamically executes R code. Much is the same as above, except for the way we get the data from the database via the context object `ctx`. See detailed information in [Exasol User Manual](https://www.exasol.com/support/secure/attachment/70209/EXASOL_User_Manual-6.1.0-en.pdf).\n",
    "\n",
    "``` sql\n",
    "-- 1. Create prediction function\n",
    "CREATE OR REPLACE R SET SCRIPT r_demo.predict3(...) EMITS (id INT, RealValue DOUBLE, Prediction DOUBLE) AS\n",
    "\n",
    "# Load library\n",
    "library(randomForest)\n",
    "\n",
    "# Get number of columns\n",
    "numCols <- exa$meta$input_column_count\n",
    "\n",
    "# Create empty list with length numCols\n",
    "l = vector(\"list\", numCols)\n",
    "\n",
    "run <- function(ctx) {\n",
    "\n",
    "  # Load the model from the bucket\n",
    "  rf_model = readRDS(\"/buckets/bucketfs1/bucket1/rf_model\")\n",
    "\n",
    "  # ...or depending on the file type\n",
    "  #load(\"/buckets/bucketfs1/bucket1/rf_model.dat\")\n",
    "\n",
    "  # Split input into modest sized chunks, this can be adjusted for memory consumption\n",
    "  repeat{\n",
    "    if (!ctx$next_row(1000000))\n",
    "        break\n",
    "\n",
    "  # Populate list with data columns\n",
    "  for (i in 1:numCols){\n",
    "\n",
    "        l[[i]] <- ctx[[i]]()\n",
    "\n",
    "  }\n",
    "\n",
    "  # Convert to data.frame for modelling\n",
    "  df = as.data.frame(l)\n",
    "\n",
    "  # Set the column names\n",
    "\n",
    "  # From the model object, note: model/scenario specific\n",
    "  # the_colnames <- names(rf_model$forest$xlevels)\n",
    "  # colnames(df) = the_colnames\n",
    "\n",
    "  # Assign manually, note: not dynamic\n",
    "  # Note: case sensitive when using double quotes\n",
    "  colnames(df) <- c(\"id\", \"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\",\n",
    "  \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\", \"split\")\n",
    "\n",
    "  # Get predictions\n",
    "  prediction   <- predict(rf_model, newdata = df)\n",
    "\n",
    "  # Output ids, real values and predicted ones\n",
    "  ctx$emit(df$id, df$medv, prediction)\n",
    "  }\n",
    "}\n",
    "/\n",
    "\n",
    "-- 2. Run prediction function\n",
    "SELECT r_demo.predict3(id,crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, b, lstat, medv, split)\n",
    "FROM   r_demo.boston_housing\n",
    "WHERE  split = 'Test'\n",
    "GROUP  BY IPROC()         -- Node number for data locality\n",
    "        , MOD(ROWNUM, 5) -- Number of processes per node\n",
    "ORDER  BY id;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
