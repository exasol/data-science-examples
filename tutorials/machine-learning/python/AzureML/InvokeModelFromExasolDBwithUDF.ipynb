{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy the trained Model and invoke it using Exasol\n",
    "\n",
    "In this part of the tutorial we will show how to deploy and invoke the trained model using Exasol. For this we will show two versions.\n",
    "You can either:\n",
    "\n",
    "\n",
    "   * [Deploy the model using an AzureML online Endpoint and then invoke it via an Exasol UDF](#deploy-the-model-in-an-azureml-endpoint)\n",
    "\n",
    "Or:\n",
    "   * [Load the model into Exasols Filesystem (BucketFS), and then deploy and invoke it via an Exasol UDF](#deplay-and-invoke-the-model-in-exasol)\n",
    "\n",
    "Which version you choose is up to you.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy the model in an AzureML endpoint\n",
    "\n",
    "In this Section we will explain how to Deploy the model in an AzureML endpoint, and the invoke it via an Exasol UDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prerequisites\n",
    " ## TODO\n",
    " * AzureML\n",
    " * Compute\n",
    " * trained and registered model\n",
    " * exasol with dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create online endpoint in azureml\n",
    "\n",
    "First we need to set up an online endpoint with our trained and registered model in AzureML, so we can use it for real time inferencing. We will do this using Python in an AzureML Notebook. You can find the AzureML tutorial for this [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?view=azureml-api-2&tabs=python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load this notebook into your AzureML Notebooks and start your Compute. Then we can install some dependencies if not already installed from previous steps."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install azure-identity\n",
    "!pip install azure-ai-ml==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [319]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mazure\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mml\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLClient\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mazure\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mentities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     ManagedOnlineEndpoint,\n\u001B[1;32m      4\u001B[0m     ManagedOnlineDeployment,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m     CodeConfiguration,\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mazure\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01midentity\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DefaultAzureCredential\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'azure'"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can enter our Credentials to access our workspace."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<your subscription id>\",               # change\n",
    "    resource_group_name=\"<your resource group name>\",       # change\n",
    "    workspace_name=\"<your workspace name>\",                 # change\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are set up to start to set up our online endpoint we then want to deploy our model in. We set it up with key authentication, but you could use token authentication instead."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define an endpoint name\n",
    "endpoint_name = \"<your-endpoint-name>\"                      # change\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name = endpoint_name,\n",
    "    description=\"<some description>\",                       # change\n",
    "    auth_mode=\"key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the Endpoint."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make a Deployment for the model\n",
    "\n",
    "We now need to Deploy our model to the Endpoint via an AzureML Deployment. For this we need an Environment definition which can run our model. This need to include the \"azureml-inference-server-http\" package. There are also ready made images available from Microsoft, but here we make our own.\n",
    "We take the conda file that is saved in our registered MLflow model and edit it to include the \"azureml-inference-server-http\" package. Then write it to a file.\n",
    "#### (TODO explain how find?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%writefile ./conda.yml\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.8.16\n",
    "- pip<=23.1.2\n",
    "- pip:\n",
    "  - azureml-inference-server-http\n",
    "  - mlflow==1.26.1\n",
    "  - cloudpickle==2.2.1\n",
    "  - scikit-learn==1.0.2\n",
    "name: endpoint-env"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we get a handle to our registered model and create the Environment for our Deployment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model = ml_client.models.get(name=\"<your registered model name>\", version=\"<version of your model you want to use>\")  # change\n",
    "\n",
    "env = Environment(\n",
    "    name=\"<name the Environment>\",                                      # change\n",
    "    description=\"Custom environment for azureML tutorial endpoint\",\n",
    "    conda_file=\"./conda.yml\",                                           # change if necessary, path to your conda.yaml fil we created earlier\n",
    "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu20.04-py38-cpu-inference:latest\", # base image from microsoft we use\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With this we now can create our Deployment.\n",
    "The Deployment uses a [scoring script](score.py). This script has an \"init()\" function which loads the model, and a \"run\" function which takes the input data and feeds it to the model. This function returns the classification results. Make sure you have the scoring script in your AzureML files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CodeConfiguration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [320]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m cc \u001B[38;5;241m=\u001B[39m \u001B[43mCodeConfiguration\u001B[49m(code\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, scoring_script\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore.py\u001B[39m\u001B[38;5;124m\"\u001B[39m)     \u001B[38;5;66;03m# change if necessary to point to your scoring script in AzureML\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model_deployment \u001B[38;5;241m=\u001B[39m ManagedOnlineDeployment(\n\u001B[1;32m      3\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<name your deployment>\u001B[39m\u001B[38;5;124m\"\u001B[39m,          \u001B[38;5;66;03m# change\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     endpoint_name\u001B[38;5;241m=\u001B[39mendpoint_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m     instance_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CodeConfiguration' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cc = CodeConfiguration(code=\".\", scoring_script=\"score.py\")     # change if necessary to point to your scoring script in AzureML\n",
    "model_deployment = ManagedOnlineDeployment(\n",
    "    name=\"<name your deployment>\",          # change\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=cc,\n",
    "    instance_type=\"Standard_DS1_v2\",        # Type of Azure Instance. You can change this if you need more computing power\n",
    "    instance_count=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can create the Deployment on our endpoint."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(model_deployment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can check the status of your Deployment by geting the logs with this comand. Alternativly you can also Navigate to your Deployment in AzureML in your Browser and chack status and logs there.\n",
    "### todo screenshots?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"<your deployment name>\", endpoint_name=endpoint_name, lines=50\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to access this Endpoint we will need a key (or a token if you choose to go with token authentication above). Get the key like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint_key = ml_client.online_endpoints.get_keys(name=endpoint_name)\n",
    "print(endpoint_key.primary_key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invoke the Endpoint from Exasol\n",
    "\n",
    "In order to invoke our deployed Endpoint, we first need access to our Exasol Saas Database. We will use pyExasol for this.\n",
    "### todo link"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyexasol in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (0.24.0)\r\n",
      "Requirement already satisfied: pyopenssl in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from pyexasol) (22.0.0)\r\n",
      "Requirement already satisfied: websocket-client>=1.0.1 in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from pyexasol) (1.2.3)\r\n",
      "Requirement already satisfied: rsa in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from pyexasol) (4.8)\r\n",
      "Requirement already satisfied: cryptography>=35.0 in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from pyopenssl->pyexasol) (36.0.1)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from cryptography>=35.0->pyopenssl->pyexasol) (1.15.0)\r\n",
      "Requirement already satisfied: pycparser in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl->pyexasol) (2.21)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/marlene/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages (from rsa->pyexasol) (0.4.8)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 23.2.1 is available.\r\n",
      "You should consider upgrading via the '/home/marlene/PycharmProjects/data-science-examples/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyexasol\n",
    "import pyexasol\n",
    "EXASOL_HOST = \"<your>.clusters.exasol.com\"      # change\n",
    "EXASOL_PORT = \"8563\"                            # change if needed\n",
    "EXASOL_USER = \"<your-exasol-user>\"              # change\n",
    "EXASOL_PASSWORD = \"exa_pat_<your_password>\"     # change\n",
    "EXASOL_SCHEMA = \"IDA\"                           # change if needed\n",
    "\n",
    "EXASOL_CONNECTION = \"{host}:{port}\".format(host=EXASOL_HOST, port=EXASOL_PORT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "exasol = pyexasol.connect(dsn=EXASOL_CONNECTION, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "<ExaStatement session_id=1777553926653673474 stmt_idx=86>"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_open_schema = \"\"\"OPEN SCHEMA \"IDA\";\"\"\"\n",
    "\n",
    "sql_create_invoke_endpoint =\"\"\"\n",
    "CREATE OR REPLACE PYTHON3 SCALAR SCRIPT IDA.invoke_endpoint(...)\n",
    "EMITS (\"ID\" DECIMAL(20,0), \"result\" VARCHAR(500), \"df\" VARCHAR(5000)) AS\n",
    "\n",
    "import urllib.request\n",
    "import requests\n",
    "import ujson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def run(ctx):\n",
    "    endpoint_key = \"dVXtOJvU5ah4OGc4ygzuzyXoSfwVvyvS\"\n",
    "    deployment_name = \"blue\"\n",
    "    headers = {'Content-Type':'application/json',\n",
    "                'Authorization': f'Bearer {endpoint_key}',\n",
    "               'azureml-model-deployment': f'{deployment_name}'}\n",
    "    scoring_url = \"https://azureml-tut-endpoint.westeurope.inference.ml.azure.com/score\"\n",
    "\n",
    "    try:\n",
    "        df = ctx.get_dataframe(10)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    if df is None:\n",
    "        return 1\n",
    "    id_column = df[\"0\"]\n",
    "    df = df.drop(\"0\", 1)\n",
    "\n",
    "    time.sleep(0.07)\n",
    "    df = df.apply(pd.to_numeric, downcast='float', errors='ignore')\n",
    "    df_str = str((df.values).tolist())\n",
    "    df_str = df_str.replace(\"nan\", 'null')\n",
    "    if len(df_str) < 20:\n",
    "        return 0\n",
    "    PARAMS = '{\"data\": ' + df_str + '}'\n",
    "\n",
    "    try:\n",
    "        result = requests.post(url=scoring_url, data=PARAMS, headers=headers)\n",
    "    except:\n",
    "        return 0\n",
    "    ctx.emit(*id_column, result.text,  df_str)\n",
    "    return 0\n",
    "/\n",
    "\"\"\"\n",
    "exasol.execute(sql_open_schema)\n",
    "exasol.execute(sql_create_invoke_endpoint)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "column_names = ['AA_000', 'AG_005', 'AH_000', 'AL_000', 'AM_0', 'AN_000', 'AO_000', 'AP_000', 'AQ_000',\n",
    "                    'AZ_004', 'BA_002', 'BB_000', 'BC_000', 'BD_000', 'BE_000',\n",
    "                    'BF_000', 'BG_000', 'BH_000', 'BI_000', 'BJ_000', 'BS_000', 'BT_000', 'BU_000', 'BV_000',\n",
    "                    'BX_000', 'BY_000', 'BZ_000', 'CA_000', 'CB_000', 'CC_000', 'CI_000', 'CN_004', 'CQ_000',\n",
    "                    'CS_001', 'DD_000', 'DE_000', 'DN_000', 'DS_000', 'DU_000', 'DV_000', 'EB_000', 'EE_005'] #todo remove class pos, also from endpoint score script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "res = exasol.export_to_pandas(\"\"\"SELECT \"CLASS\", \"result\", \"df\" FROM  (\n",
    "                           SELECT IDA.invoke_endpoint(ROWID, {columns!q}) FROM IDA.TEST t) r\n",
    "                           JOIN IDA.TEST o ON r.ID = o.ROWID\"\"\", {\"columns\": column_names})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "data": {
      "text/plain": "      CLASS           result  \\\n0       neg  {\"result\": \"0\"}   \n1       neg  {\"result\": \"1\"}   \n2       neg  {\"result\": \"0\"}   \n3       neg  {\"result\": \"0\"}   \n4       neg  {\"result\": \"0\"}   \n...     ...              ...   \n15828   neg  {\"result\": \"0\"}   \n15829   neg  {\"result\": \"0\"}   \n15830   pos  {\"result\": \"1\"}   \n15831   neg  {\"result\": \"0\"}   \n15832   neg  {\"result\": \"0\"}   \n\n                                                      df  \n0      [[32.0, 5752.0, 3490.0, 0.0, 0.0, 17204.0, 147...  \n1      [[601272.0, 32486.0, 17128568.0, 335184.0, 482...  \n2      [[16.0, 5406.0, 3032.0, 0.0, 0.0, 11154.0, 674...  \n3      [[45416.0, 2297994.0, 1786606.0, 0.0, 0.0, 472...  \n4      [[62714.0, 265216.0, 1826092.0, 0.0, 0.0, 3971...  \n...                                                  ...  \n15828  [[7460.0, 339610.0, 306840.0, 0.0, 0.0, 534406...  \n15829  [[40490.0, 1176332.0, 979148.0, 0.0, 0.0, 2050...  \n15830  [[62724.0, 4043362.0, 5003048.0, 373276.0, 486...  \n15831  [[30744.0, 245024.0, 1074244.0, 0.0, 0.0, 1927...  \n15832  [[19476.0, 0.0, 2861712.0, 77018.0, 105798.0, ...  \n\n[15833 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CLASS</th>\n      <th>result</th>\n      <th>df</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[32.0, 5752.0, 3490.0, 0.0, 0.0, 17204.0, 147...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neg</td>\n      <td>{\"result\": \"1\"}</td>\n      <td>[[601272.0, 32486.0, 17128568.0, 335184.0, 482...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[16.0, 5406.0, 3032.0, 0.0, 0.0, 11154.0, 674...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[45416.0, 2297994.0, 1786606.0, 0.0, 0.0, 472...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[62714.0, 265216.0, 1826092.0, 0.0, 0.0, 3971...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15828</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[7460.0, 339610.0, 306840.0, 0.0, 0.0, 534406...</td>\n    </tr>\n    <tr>\n      <th>15829</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[40490.0, 1176332.0, 979148.0, 0.0, 0.0, 2050...</td>\n    </tr>\n    <tr>\n      <th>15830</th>\n      <td>pos</td>\n      <td>{\"result\": \"1\"}</td>\n      <td>[[62724.0, 4043362.0, 5003048.0, 373276.0, 486...</td>\n    </tr>\n    <tr>\n      <th>15831</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[30744.0, 245024.0, 1074244.0, 0.0, 0.0, 1927...</td>\n    </tr>\n    <tr>\n      <th>15832</th>\n      <td>neg</td>\n      <td>{\"result\": \"0\"}</td>\n      <td>[[19476.0, 0.0, 2861712.0, 77018.0, 105798.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15833 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "predictions  \\nPlease check this guide to understand why this error code might have been returned \\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\\n  \\\nactuals                                                                                                                                                                                                                \nneg                                                       1655                                                                                                                                                         \npos                                                         29                                                                                                                                                         \n\npredictions  upstream connect error or disconnect/reset before headers. reset reason: overflow\\nPlease check this guide to understand why this error code might have been returned \\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\\n  \\\nactuals                                                                                                                                                                                                                                                                                                 \nneg                                                          4                                                                                                                                                                                                                                          \npos                                                          0                                                                                                                                                                                                                                          \n\npredictions  {\"result\": \"0\"}  {\"result\": \"1\"}  \nactuals                                        \nneg                    13106              697  \npos                       12              330  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>predictions</th>\n      <th>\\nPlease check this guide to understand why this error code might have been returned \\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\\n</th>\n      <th>upstream connect error or disconnect/reset before headers. reset reason: overflow\\nPlease check this guide to understand why this error code might have been returned \\nhttps://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\\n</th>\n      <th>{\"result\": \"0\"}</th>\n      <th>{\"result\": \"1\"}</th>\n    </tr>\n    <tr>\n      <th>actuals</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>neg</th>\n      <td>1655</td>\n      <td>4</td>\n      <td>13106</td>\n      <td>697</td>\n    </tr>\n    <tr>\n      <th>pos</th>\n      <td>29</td>\n      <td>0</td>\n      <td>12</td>\n      <td>330</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# print( res.loc[res[\"prediction\"] == 0])\n",
    "pd.crosstab(index=res['CLASS'], columns=res[\"result\"], rownames=['actuals'], colnames=['predictions'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exasol.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and invoke the model in Exasol\n",
    "\n",
    "intoduce"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prerequisites\n",
    "\n",
    "### TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyexasol\n",
    "import pyexasol\n",
    "import pandas as pd\n",
    "\n",
    "EXASOL_HOST = \"<your>.clusters.exasol.com\"      # change\n",
    "EXASOL_PORT = \"8563\"                            # change if needed\n",
    "EXASOL_USER = \"<your-exasol-user>\"              # change\n",
    "EXASOL_PASSWORD = \"exa_pat_<your_password>\"     # change\n",
    "EXASOL_SCHEMA = \"IDA\"                           # change if needed\n",
    "\n",
    "# get the connection\n",
    "EXASOL_CONNECTION = \"{host}:{port}\".format(host=EXASOL_HOST, port=EXASOL_PORT)\n",
    "exasol = pyexasol.connect(dsn=EXASOL_CONNECTION, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>AA_000</th>\n",
       "      <th>AB_000</th>\n",
       "      <th>AC_000</th>\n",
       "      <th>AD_000</th>\n",
       "      <th>AE_000</th>\n",
       "      <th>AF_000</th>\n",
       "      <th>AG_000</th>\n",
       "      <th>AG_001</th>\n",
       "      <th>AG_002</th>\n",
       "      <th>...</th>\n",
       "      <th>EE_002</th>\n",
       "      <th>EE_003</th>\n",
       "      <th>EE_004</th>\n",
       "      <th>EE_005</th>\n",
       "      <th>EE_006</th>\n",
       "      <th>EE_007</th>\n",
       "      <th>EE_008</th>\n",
       "      <th>EE_009</th>\n",
       "      <th>EF_000</th>\n",
       "      <th>EG_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>42434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>339654</td>\n",
       "      <td>149990</td>\n",
       "      <td>376978</td>\n",
       "      <td>289532</td>\n",
       "      <td>215998</td>\n",
       "      <td>144972</td>\n",
       "      <td>250588</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2992</td>\n",
       "      <td>...</td>\n",
       "      <td>4142</td>\n",
       "      <td>2110</td>\n",
       "      <td>9332</td>\n",
       "      <td>22310</td>\n",
       "      <td>936</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>21386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>229972</td>\n",
       "      <td>91158</td>\n",
       "      <td>95770</td>\n",
       "      <td>55132</td>\n",
       "      <td>70446</td>\n",
       "      <td>397896</td>\n",
       "      <td>1106</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS  AA_000  AB_000        AC_000  AD_000  AE_000  AF_000  AG_000  AG_001  \\\n",
       "0   neg   42434     NaN  2.130706e+09     NaN     0.0     0.0       0       0   \n",
       "1   neg     852     NaN  8.000000e+01    66.0     0.0     0.0       0       0   \n",
       "2   neg     436     0.0  6.600000e+01    60.0     0.0     0.0       0       0   \n",
       "3   neg   21386     NaN           NaN     NaN     NaN     NaN       0       0   \n",
       "\n",
       "   AG_002  ...  EE_002  EE_003  EE_004  EE_005  EE_006  EE_007  EE_008  \\\n",
       "0       0  ...  339654  149990  376978  289532  215998  144972  250588   \n",
       "1    2992  ...    4142    2110    9332   22310     936     222       0   \n",
       "2       0  ...       0       0       0       0       0       0       0   \n",
       "3       0  ...  229972   91158   95770   55132   70446  397896    1106   \n",
       "\n",
       "   EE_009  EF_000  EG_000  \n",
       "0    1408     0.0     0.0  \n",
       "1       0     0.0     0.0  \n",
       "2       0     0.0     0.0  \n",
       "3     180     NaN     NaN  \n",
       "\n",
       "[4 rows x 171 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exasol.export_to_pandas(\"SELECT * FROM IDA.TRAIN LIMIT 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! curl -X PUT -T sklearn_model.tgz https://w:writepw@192.168.6.75:1234/bucket1/my_file.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! curl -X PUT -T tar1.tgz https://w:writepw@192.168.6.75:1234/bucket1/my_file.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, move model from AzureML to Exasol BucketFS.\n",
    "open saas, start db, clck manage udf files, click new de, upload file (only works in enterprise edition)\n",
    "copy path of file\n",
    "\n",
    "## call and invoke using udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExaStatement session_id=1774377255978401792 stmt_idx=1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_open_schema = \"\"\"OPEN SCHEMA \"IDA\";\"\"\"\n",
    "sql_ls = \"\"\" --/\n",
    "CREATE OR REPLACE PYTHON3 SCALAR SCRIPT \"IDA.LS\" (\"my_path\" VARCHAR(100)) EMITS (\"FILES\" VARCHAR(100)) AS\n",
    "import os\n",
    "def run(ctx):\n",
    "    for line in os.listdir(ctx.my_path):\n",
    "        ctx.emit(line)\n",
    "/\n",
    "\"\"\"\n",
    "\n",
    "sgl_run_ls = \"\"\"SELECT \"IDA.LS\"('/buckets/uploads/default/testfolder');\"\"\"\n",
    "\n",
    "exasol.execute(sql_open_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExaStatement session_id=1774293578104963073 stmt_idx=16>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exasol.execute(sql_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FILES\n",
       "0  model.pkl"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exasol.export_to_pandas(sgl_run_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "ename": "ExaCommunicationError",
     "evalue": "\n(\n    message     =>  [Errno 32] Broken pipe\n    dsn         =>  6ki32oqp7zdtdldmii5e256npi.clusters.exasol.com:8563\n    user        =>  integration-team\n    schema      =>  \n    session_id  =>  1774556523641896962\n)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:524\u001B[0m, in \u001B[0;36mExaConnection.req\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m    522\u001B[0m start_ts \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 524\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ws_send\u001B[49m\u001B[43m(\u001B[49m\u001B[43msend_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m recv_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ws_recv()\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:611\u001B[0m, in \u001B[0;36mExaConnection._login.<locals>.<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m--> 611\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ws_send \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ws\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_binary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ws_recv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m: zlib\u001B[38;5;241m.\u001B[39mdecompress(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ws\u001B[38;5;241m.\u001B[39mrecv())\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_core.py:325\u001B[0m, in \u001B[0;36mWebSocket.send_binary\u001B[0;34m(self, payload)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03mSend a binary message (OPCODE_BINARY).\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;124;03m    payload of message to send.\u001B[39;00m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 325\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mABNF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOPCODE_BINARY\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_core.py:283\u001B[0m, in \u001B[0;36mWebSocket.send\u001B[0;34m(self, payload, opcode)\u001B[0m\n\u001B[1;32m    282\u001B[0m frame \u001B[38;5;241m=\u001B[39m ABNF\u001B[38;5;241m.\u001B[39mcreate_frame(payload, opcode)\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_core.py:311\u001B[0m, in \u001B[0;36mWebSocket.send_frame\u001B[0;34m(self, frame)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m data:\n\u001B[0;32m--> 311\u001B[0m     l \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m     data \u001B[38;5;241m=\u001B[39m data[l:]\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_core.py:525\u001B[0m, in \u001B[0;36mWebSocket._send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_send\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m--> 525\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_socket.py:173\u001B[0m, in \u001B[0;36msend\u001B[0;34m(sock, data)\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 173\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_send\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/websocket/_socket.py:150\u001B[0m, in \u001B[0;36msend.<locals>._send\u001B[0;34m()\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLWantWriteError:\n",
      "File \u001B[0;32m/usr/lib/python3.8/ssl.py:1173\u001B[0m, in \u001B[0;36mSSLSocket.send\u001B[0;34m(self, data, flags)\u001B[0m\n\u001B[1;32m   1170\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1171\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to send() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mExaCommunicationError\u001B[0m                     Traceback (most recent call last)",
      "Input \u001B[0;32mIn [95]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m sql_create_inferece_udf \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124m--/\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124mCREATE OR REPLACE PYTHON3 SCALAR SCRIPT IDA.use_model_for_inference(...)\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124m/\u001B[39m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 38\u001B[0m \u001B[43mexasol\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql_create_inferece_udf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:194\u001B[0m, in \u001B[0;36mExaConnection.execute\u001B[0;34m(self, query, query_params)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m, query, query_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ExaStatement:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m    Execute SQL query with optional query formatting parameters\u001B[39;00m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;124;03m    Return ExaStatement object\u001B[39;00m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcls_statement\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/statement.py:55\u001B[0m, in \u001B[0;36mExaStatement.__init__\u001B[0;34m(self, connection, query, query_params, prepare, meta_nosql, **options)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_meta_nosql()\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 55\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/statement.py:157\u001B[0m, in \u001B[0;36mExaStatement._execute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcommand\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexecute\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msqlText\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecution_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mws_req_time\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_result_set(ret)\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:530\u001B[0m, in \u001B[0;36mExaConnection.req\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (websocket\u001B[38;5;241m.\u001B[39mWebSocketException, \u001B[38;5;167;01mConnectionError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose(disconnect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m--> 530\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ExaCommunicationError(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_req_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "\u001B[0;31mExaCommunicationError\u001B[0m: \n(\n    message     =>  [Errno 32] Broken pipe\n    dsn         =>  6ki32oqp7zdtdldmii5e256npi.clusters.exasol.com:8563\n    user        =>  integration-team\n    schema      =>  \n    session_id  =>  1774556523641896962\n)\n"
     ]
    }
   ],
   "source": [
    "sql_create_inferece_udf = \"\"\"\n",
    "--/\n",
    "CREATE OR REPLACE PYTHON3 SCALAR SCRIPT IDA.use_model_for_inference(...)\n",
    "EMITS (\"ID\" DECIMAL(20,0), \"prediction\" DOUBLE) AS\n",
    "\n",
    "import urllib.request\n",
    "import lxml.etree as etree\n",
    "import sklearn\n",
    "import numpy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def load_model():\n",
    "    model_path = \"/buckets/uploads/default/testfolder/model.pkl\"  # change to your model file path\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = pickle.load(open(model_path, 'rb'))\n",
    "    return model\n",
    "\n",
    "def infer(data, model):\n",
    "\n",
    "    data = numpy.array(data)\n",
    "    result = model.predict(data)\n",
    "    return result\n",
    "\n",
    "\n",
    "def run(ctx):\n",
    "    model = load_model()\n",
    "    df = ctx.get_dataframe(num_rows=100)\n",
    "\n",
    "    id_column = df[\"0\"]\n",
    "    df = df.drop(\"0\", 1)\n",
    "    response = infer(df, model)\n",
    "    result = pd.DataFrame(response)\n",
    "    ctx.emit(pd.concat([id_column,result],axis=1))\n",
    "\n",
    "/\n",
    "\"\"\"\n",
    "exasol.execute(sql_create_inferece_udf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "column_names = ['AA_000', 'AG_005', 'AH_000', 'AL_000', 'AM_0', 'AN_000', 'AO_000', 'AP_000', 'AQ_000',\n",
    "                    'AZ_004', 'BA_002', 'BB_000', 'BC_000', 'BD_000', 'BE_000',\n",
    "                    'BF_000', 'BG_000', 'BH_000', 'BI_000', 'BJ_000', 'BS_000', 'BT_000', 'BU_000', 'BV_000',\n",
    "                    'BX_000', 'BY_000', 'BZ_000', 'CA_000', 'CB_000', 'CC_000', 'CI_000', 'CN_004', 'CQ_000',\n",
    "                    'CS_001', 'DD_000', 'DE_000', 'DN_000', 'DS_000', 'DU_000', 'DV_000', 'EB_000', 'EE_005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ExaQueryError",
     "evalue": "\n(\n    message     =>  VM error: F-UDF-CL-LIB-1127: F-UDF-CL-SL-PYTHON-1002: F-UDF-CL-SL-PYTHON-1026: ExaUDFError: F-UDF-CL-SL-PYTHON-1114: Exception during run \nUSE_MODEL_FOR_INFERENCE:23 run\nRuntimeError: E-UDF-CL-SL-PYTHON-1105: get_dataframe() parameter 'start_col' is 6000, but there are only 43 input columns\n (Session: 1774556523641896962)\n    dsn         =>  6ki32oqp7zdtdldmii5e256npi.clusters.exasol.com:8563\n    user        =>  integration-team\n    schema      =>  \n    session_id  =>  1774556523641896962\n    code        =>  22002\n    query       =>  EXPORT (\nSELECT \"CLASS\", \"prediction\" FROM  (\n                           SELECT IDA.use_model_for_inference(ROWID, \"AA_000\", \"AG_005\", \"AH_000\", \"AL_000\", \"AM_0\", \"AN_000\", \"AO_000\", \"AP_000\", \"AQ_000\", \"AZ_004\", \"BA_002\", \"BB_000\", \"BC_000\", \"BD_000\", \"BE_000\", \"BF_000\", \"BG_000\", \"BH_000\", \"BI_000\", \"BJ_000\", \"BS_000\", \"BT_000\", \"BU_000\", \"BV_000\", \"BX_000\", \"BY_000\", \"BZ_000\", \"CA_000\", \"CB_000\", \"CC_000\", \"CI_000\", \"CN_004\", \"CQ_000\", \"CS_001\", \"DD_000\", \"DE_000\", \"DN_000\", \"DS_000\", \"DU_000\", \"DV_000\", \"EB_000\", \"EE_005\") FROM IDA.TEST t) r\n                           JOIN IDA.TEST o ON r.ID = o.ROWID\n) INTO CSV\nAT 'https://172.16.59.37:44821' FILE '000.gz'\nWITH COLUMN NAMES\n)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mEmptyDataError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1231\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1230\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1232\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:75\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     74\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m ensure_dtype_objs(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader \u001B[38;5;241m=\u001B[39m \u001B[43mparsers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTextReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munnamed_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39munnamed_cols\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:551\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mEmptyDataError\u001B[0m: No columns to parse from file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:314\u001B[0m, in \u001B[0;36mExaConnection.export_to_callback\u001B[0;34m(self, callback, dst, query_or_table, query_params, callback_params, export_params)\u001B[0m\n\u001B[1;32m    312\u001B[0m sql_thread\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m--> 314\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_pipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcallback_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    315\u001B[0m http_thread\u001B[38;5;241m.\u001B[39mread_pipe\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/callback.py:42\u001B[0m, in \u001B[0;36mexport_to_pandas\u001B[0;34m(pipe, dst, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_blank_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1234\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandles\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1235\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pandas/io/common.py:112\u001B[0m, in \u001B[0;36mIOHandles.close\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, TextIOWrapper)\n\u001B[0;32m--> 112\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle\u001B[38;5;241m.\u001B[39mdetach()\n",
      "\u001B[0;31mValueError\u001B[0m: I/O operation on closed file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mExaQueryError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [94]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mexasol\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport_to_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[38;5;124;43mSELECT \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCLASS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m FROM  (\u001B[39;49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;43m                           SELECT IDA.use_model_for_inference(ROWID, \u001B[39;49m\u001B[38;5;124;43m{\u001B[39;49m\u001B[38;5;124;43mcolumns_without_class!q}) FROM IDA.TEST t) r\u001B[39;49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;43m                           JOIN IDA.TEST o ON r.ID = o.ROWID\u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns_without_class\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_names\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:279\u001B[0m, in \u001B[0;36mExaConnection.export_to_pandas\u001B[0;34m(self, query_or_table, query_params, callback_params, export_params)\u001B[0m\n\u001B[1;32m    275\u001B[0m     export_params \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    277\u001B[0m export_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwith_column_names\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport_to_callback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport_to_pandas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_or_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:335\u001B[0m, in \u001B[0;36mExaConnection.export_to_callback\u001B[0;34m(self, callback, dst, query_or_table, query_params, callback_params, export_params)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;66;03m# Give SQL exception higher priority\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sql_thread\u001B[38;5;241m.\u001B[39mexc:\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m sql_thread\u001B[38;5;241m.\u001B[39mexc\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/http_transport.py:35\u001B[0m, in \u001B[0;36mExaSQLThread.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 35\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc \u001B[38;5;241m=\u001B[39m e\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/http_transport.py:156\u001B[0m, in \u001B[0;36mExaSQLExportThread.run_sql\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwith_column_names\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    154\u001B[0m     parts\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWITH COLUMN NAMES\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 156\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparts\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:194\u001B[0m, in \u001B[0;36mExaConnection.execute\u001B[0;34m(self, query, query_params)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m, query, query_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ExaStatement:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m    Execute SQL query with optional query formatting parameters\u001B[39;00m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;124;03m    Return ExaStatement object\u001B[39;00m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcls_statement\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/statement.py:55\u001B[0m, in \u001B[0;36mExaStatement.__init__\u001B[0;34m(self, connection, query, query_params, prepare, meta_nosql, **options)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_meta_nosql()\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 55\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/statement.py:157\u001B[0m, in \u001B[0;36mExaStatement._execute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcommand\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexecute\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msqlText\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecution_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mws_req_time\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_result_set(ret)\n",
      "File \u001B[0;32m~/PycharmProjects/data-science-examples/venv/lib/python3.8/site-packages/pyexasol/connection.py:558\u001B[0m, in \u001B[0;36mExaConnection.req\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    556\u001B[0m         cls_err \u001B[38;5;241m=\u001B[39m ExaQueryError\n\u001B[0;32m--> 558\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m cls_err(\u001B[38;5;28mself\u001B[39m, req[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqlText\u001B[39m\u001B[38;5;124m'\u001B[39m], ret[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexception\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqlCode\u001B[39m\u001B[38;5;124m'\u001B[39m], ret[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexception\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m req\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musername\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    560\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ExaAuthError(\u001B[38;5;28mself\u001B[39m, ret[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexception\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqlCode\u001B[39m\u001B[38;5;124m'\u001B[39m], ret[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexception\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mExaQueryError\u001B[0m: \n(\n    message     =>  VM error: F-UDF-CL-LIB-1127: F-UDF-CL-SL-PYTHON-1002: F-UDF-CL-SL-PYTHON-1026: ExaUDFError: F-UDF-CL-SL-PYTHON-1114: Exception during run \nUSE_MODEL_FOR_INFERENCE:23 run\nRuntimeError: E-UDF-CL-SL-PYTHON-1105: get_dataframe() parameter 'start_col' is 6000, but there are only 43 input columns\n (Session: 1774556523641896962)\n    dsn         =>  6ki32oqp7zdtdldmii5e256npi.clusters.exasol.com:8563\n    user        =>  integration-team\n    schema      =>  \n    session_id  =>  1774556523641896962\n    code        =>  22002\n    query       =>  EXPORT (\nSELECT \"CLASS\", \"prediction\" FROM  (\n                           SELECT IDA.use_model_for_inference(ROWID, \"AA_000\", \"AG_005\", \"AH_000\", \"AL_000\", \"AM_0\", \"AN_000\", \"AO_000\", \"AP_000\", \"AQ_000\", \"AZ_004\", \"BA_002\", \"BB_000\", \"BC_000\", \"BD_000\", \"BE_000\", \"BF_000\", \"BG_000\", \"BH_000\", \"BI_000\", \"BJ_000\", \"BS_000\", \"BT_000\", \"BU_000\", \"BV_000\", \"BX_000\", \"BY_000\", \"BZ_000\", \"CA_000\", \"CB_000\", \"CC_000\", \"CI_000\", \"CN_004\", \"CQ_000\", \"CS_001\", \"DD_000\", \"DE_000\", \"DN_000\", \"DS_000\", \"DU_000\", \"DV_000\", \"EB_000\", \"EE_005\") FROM IDA.TEST t) r\n                           JOIN IDA.TEST o ON r.ID = o.ROWID\n) INTO CSV\nAT 'https://172.16.59.37:44821' FILE '000.gz'\nWITH COLUMN NAMES\n)\n"
     ]
    }
   ],
   "source": [
    "res = exasol.export_to_pandas(\"\"\"SELECT \"CLASS\", \"prediction\" FROM  (\n",
    "                           SELECT IDA.use_model_for_inference(ROWID, {columns_without_class!q}) FROM IDA.TEST t) r\n",
    "                           JOIN IDA.TEST o ON r.ID = o.ROWID\"\"\", {\"columns_without_class\": column_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "predictions      0    1\nactuals                \nneg          14841  784\npos             13  362",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>predictions</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>actuals</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>neg</th>\n      <td>14841</td>\n      <td>784</td>\n    </tr>\n    <tr>\n      <th>pos</th>\n      <td>13</td>\n      <td>362</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# print( res.loc[res[\"prediction\"] == 0])\n",
    "pd.crosstab(index=res['CLASS'], columns=res[\"prediction\"], rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "delete udfs again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}