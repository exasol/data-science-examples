{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train an ML model on Exasol Data\n",
    "\n",
    "In this Turtorial You will load the data from Azure Blobstorage, and run a python script as an AzureML job to do some data preprocessing and train a simple tensorflow model. Then You will register the trained model with AzureML for further use.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prerequisites\n",
    "You completed the [previous part of this tutorial series](ConnectAzureMLtoExasol.ipynb) and therefore have:\n",
    " - running AzureML compute instance\n",
    " - Azure storage account\n",
    " - [Scania Trucks](https://archive.ics.uci.edu/ml/datasets/IDA2016Challenge) dataset loaded into Azure Blobstore\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Python script for training the model\n",
    "\n",
    "We will use a python script to create and train a tensorflow model on the data we loaded from Exasol. You can finde the script [here](main.py).\n",
    "The script loads the data from the files we saved in the Azure Blobstore, does some data preprocessing to combat the unbalanced nature of the dataset and remove empty values so the TensorFlow backpropagation can work properly. Then it creates a simple TensorFlow model and trains it on the data. The mode is evaluated using the test dataset and saved to the job output.\n",
    "\n",
    "This script creates a model that only uses Python packages available in Exasol Saas UDFs natively. This means you can upload this model directly to your exasol cluster and run it on the cluster using an UDF. If your own models use different packages but you still need to run them on the cluster directly you need to [build and install you own Script-Language Container](https://docs.exasol.com/db/latest/database_concepts/udf_scripts/adding_new_packages_script_languages.htm). Information on which packages are supported out of the box can be found [here](https://docs.exasol.com/saas/database_concepts/udf_scripts.htm).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare AzureML studio to run the Python script\n",
    "\n",
    "This notebook is meant to be run in AzureML Studio, so upload it to yor Notebooks, open it and select your compute instance in the drop-down menu at the top of your notebook.\n",
    "The same things could be archived accessing AzureML using remote scripts, but for demonstration purposes we use AzureML Studio here.\n",
    "\n",
    "First, we install some AzureML functionality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install azure-identity\n",
    "!pip install azure-ai-ml==1.3.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we create an MLClient for accessing our AzureML jobs programmatically. For this we need our AzureML subscription id, resource group name and workspace name. Make sure to use the workspace you set up in the previous tutorial.\n",
    "\n",
    "# TODO explain how get resource group name?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<your subscription id>\",               # change\n",
    "    resource_group_name=\"<your resource group name>\",       # change\n",
    "    workspace_name=\"<your workspace name>\",                 # change\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a new Python Environment\n",
    "\n",
    "In order to run our Pyton script we need to create a new environment and install some dependencies. For this we first create a new directory called \"dependencies\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#make env\n",
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - tensorflow\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we will create a new environment to run our job in. We will use the new dependencies file and use an ubuntu images as the base for our environment. Then we will create the new environment on our ml_client."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "custom_env_name = \"<Name your environment here>\"    # change\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for azureML tut\",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the Python script\n",
    "Now we need to create an AzureML job with some inputs, the path to the needed code, a command to run the code and information on which AzureML Compute and environment to use.\n",
    "This job will be used to run our Python script on our Compute using the environment we created in the step before.\n",
    "The script takes links to the data files we loaded ino Azure Blobstorage in the previous tutorial as input. You can find these links by\n",
    "# TODO add description and images\n",
    "Also don't forget to change the variables for your Compute.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "\n",
    "job = command(\n",
    "    inputs=dict(\n",
    "        train_data=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"< link to training data file >\",       # change\n",
    "        test_data=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"< link to test data file >\",           # change\n",
    "        ),\n",
    "        validation_data=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"< link to validation data file >\",     # change\n",
    "        ),\n",
    "        learning_rate=0.001,\n",
    "    ),\n",
    "    code=\".\",  # location of source code, change if script not in same directory as this notebook\n",
    "\n",
    "    command=\"python main.py --train_data ${{inputs.train_data}} --test_data ${{inputs.test_data}} --validation_data ${{inputs.validation_data}} --learning_rate ${{inputs.learning_rate}} \",\n",
    "    environment=pipeline_job_env,\n",
    "    compute=\"<your_compute_name>\",                      # change\n",
    "    experiment_name=\"<experiment_name>\",                # change\n",
    "    display_name=\"<experiment_name_>\",                  # change\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can run the script on our compute instance. A link will show up below which you can click on to see the job details and output logs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_client.create_or_update(job)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the trained model\n",
    "\n",
    "The Python script saves the trained model in the output files of the AzureML job. In order to register the model with AzureML we need to wait for the job to complete, and then we can create an AzureML Model instance from the tensorflow model.\n",
    "\n",
    "You can find the name of your most recent job in the output of the step above. Copy and paste it into the cde below in order to get the trained model from this specific job."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "job_name = \"sad_glass_j5n9vtm0t3\"                   # change each run!\n",
    "registered_model_name = \"trucks_defaults_model\"\n",
    "\n",
    "# stream the output and wait until the job is finished\n",
    "ml_client.jobs.stream(job_name)\n",
    "\n",
    "# refresh the latest status of the job after streaming\n",
    "job_out = ml_client.jobs.get(name=job_name)\n",
    "\n",
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "if job_out.status == \"Completed\":\n",
    "    # lets get the model from this run\n",
    "    model = Model(\n",
    "        # the script stores the model as \"model\"\n",
    "        path=\"azureml://jobs/${{job_name}}/outputs/artifacts/paths/outputs/model/\",\n",
    "        name=\"${{registered_model_name}}\",\n",
    "        description=\"Model created from run.\",\n",
    "        type=\"custom_model\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can register the model we retrieved from the job output with AzureML. This will allow us to access the model in the future and use it for inference in AzureML or download it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "registered_model = ml_client.models.create_or_update(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For us the model we trained on the Scania trucks dataset had a testing accuracy of 97,78 %.\n",
    "\n",
    "|        | 0 prediction | 1 prediction |\n",
    "|--------|--------------|--------------|\n",
    "| 0 fact | tn 15538     | fp 87        |\n",
    "| 1 fact | fn 268       | tp 107       |\n",
    "\n",
    "You can find your registered model in\n",
    "# tODO explain and add pic of rgistered model in azureML here\n",
    "\n",
    "next part,"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}