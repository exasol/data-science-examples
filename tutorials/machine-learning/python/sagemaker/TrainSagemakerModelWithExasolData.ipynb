{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train a Sagemaker model with data from Exasol\n",
    "\n",
    "This notebook shows you how to train an AWS Sagemaker model using data from withing the Exasol database.\n",
    "The trick with the Python Sagemaker SDK is, that the actual training is not run on this notebooks instance but on a dedicated EC2 instance.\n",
    "That saves costs, since you only pay for the fast and expensive training instance during training.\n",
    "The exchange is handled using an CSV file. So this notebook will write the training data as a CSV file to an S3 bucket.\n",
    "From there the training instance will read it, and write back the trained model.\n",
    "\n",
    "Typically, you prepare the data using python in this notebook (for example using pandas).\n",
    "We will, however, use a more performant approach: Instead of passing all data through this notebook,\n",
    "we will directly prepare and export them in the Exasol database using SQL.\n",
    "By that you can use the computation power of your entire Exasol cluster!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXASOL_HOST = \"<database_host>\" # change\n",
    "EXASOL_PORT = \"8563\" # change if needed\n",
    "EXASOL_USER = \"sys\" # change if needed\n",
    "EXASOL_PASSWORD = \"<database_password>\" #change\n",
    "EXASOL_SCHEMA = \"IDA\"\n",
    "\n",
    "# We will asign these tags to all resources created by this notebook. That's usefull to monitor your costs.\n",
    "# add for example: {\"Key\":\"owner\", \"Value\": \"your.name@example.com\"}\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyexasol\n",
    "\n",
    "import boto3, sys, math, os, sagemaker, pyexasol\n",
    "import numpy as np                                \n",
    "import pandas as pd                                                            \n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a connection to the Exasol database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXASOL_CONNECTION = \"{host}:{port}\".format(host=EXASOL_HOST, port=EXASOL_PORT)\n",
    "exasol = pyexasol.connect(dsn=EXASOL_CONNECTION, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take a look on our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>AA_000</th>\n",
       "      <th>AB_000</th>\n",
       "      <th>AC_000</th>\n",
       "      <th>AD_000</th>\n",
       "      <th>AE_000</th>\n",
       "      <th>AF_000</th>\n",
       "      <th>AG_000</th>\n",
       "      <th>AG_001</th>\n",
       "      <th>AG_002</th>\n",
       "      <th>...</th>\n",
       "      <th>EE_002</th>\n",
       "      <th>EE_003</th>\n",
       "      <th>EE_004</th>\n",
       "      <th>EE_005</th>\n",
       "      <th>EE_006</th>\n",
       "      <th>EE_007</th>\n",
       "      <th>EE_008</th>\n",
       "      <th>EE_009</th>\n",
       "      <th>EF_000</th>\n",
       "      <th>EG_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>41116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>199780</td>\n",
       "      <td>101244</td>\n",
       "      <td>272518</td>\n",
       "      <td>433912</td>\n",
       "      <td>372908</td>\n",
       "      <td>163418</td>\n",
       "      <td>195492</td>\n",
       "      <td>13496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>59726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>340830</td>\n",
       "      <td>201640</td>\n",
       "      <td>583574</td>\n",
       "      <td>708870</td>\n",
       "      <td>582644</td>\n",
       "      <td>227474</td>\n",
       "      <td>70738</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>30066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>258204</td>\n",
       "      <td>129524</td>\n",
       "      <td>265784</td>\n",
       "      <td>294224</td>\n",
       "      <td>199650</td>\n",
       "      <td>91130</td>\n",
       "      <td>111416</td>\n",
       "      <td>3228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>125250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>794026</td>\n",
       "      <td>510006</td>\n",
       "      <td>1348866</td>\n",
       "      <td>1101396</td>\n",
       "      <td>825410</td>\n",
       "      <td>489878</td>\n",
       "      <td>505230</td>\n",
       "      <td>5224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS  AA_000  AB_000  AC_000  AD_000  AE_000  AF_000  AG_000  AG_001  \\\n",
       "0   neg   41116     NaN       0     NaN       0       0       0       0   \n",
       "1   neg   59726     NaN      78    40.0       0       0       0       0   \n",
       "2   neg   30066     NaN     340   340.0       0       0       0       0   \n",
       "3   neg  125250     NaN       0     NaN       0       0       0       0   \n",
       "\n",
       "   AG_002  ...  EE_002  EE_003   EE_004   EE_005  EE_006  EE_007  EE_008  \\\n",
       "0       0  ...  199780  101244   272518   433912  372908  163418  195492   \n",
       "1       0  ...  340830  201640   583574   708870  582644  227474   70738   \n",
       "2       0  ...  258204  129524   265784   294224  199650   91130  111416   \n",
       "3       0  ...  794026  510006  1348866  1101396  825410  489878  505230   \n",
       "\n",
       "   EE_009  EF_000  EG_000  \n",
       "0   13496       0       0  \n",
       "1      14       0       0  \n",
       "2    3228       0       0  \n",
       "3    5224       0       0  \n",
       "\n",
       "[4 rows x 171 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exasol.export_to_pandas(\"SELECT * FROM {schema!q}.TRAIN LIMIT 4\",{\"schema\": EXASOL_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things we need to do:\n",
    "    \n",
    "* Split into train and validation data\n",
    "* Replace `CLASS` column by a column with boolean values\n",
    "\n",
    "For the split we add a column `SPLIT` that has a random value between 0 and 1, so we can partition the data by a condition on that column.\n",
    "\n",
    "In addition, we replace the `CLASS` with the text values `pos` and `neg` by a new column `CLASS_POS` with boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExaStatement session_id=1685765842211831808 stmt_idx=58>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = exasol.export_to_pandas(\"SELECT * FROM {schema!q}.TRAIN LIMIT 1;\", {\"schema\": EXASOL_SCHEMA})\n",
    "column_names = list(all_columns)\n",
    "column_names.remove(\"CLASS\")\n",
    "exasol.execute(\"\"\"CREATE OR REPLACE TABLE {schema!q}.TRAIN_PREPARED AS (\n",
    "               SELECT RANDOM() AS SPLIT,\n",
    "               (CLASS = 'pos') as CLASS_POS, {all_columns_except_class!q} FROM {schema!q}.TRAIN)\"\"\",\n",
    "               { \"schema\": EXASOL_SCHEMA, \"all_columns_except_class\": column_names})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPLIT</th>\n",
       "      <th>CLASS_POS</th>\n",
       "      <th>AA_000</th>\n",
       "      <th>AB_000</th>\n",
       "      <th>AC_000</th>\n",
       "      <th>AD_000</th>\n",
       "      <th>AE_000</th>\n",
       "      <th>AF_000</th>\n",
       "      <th>AG_000</th>\n",
       "      <th>AG_001</th>\n",
       "      <th>...</th>\n",
       "      <th>EE_002</th>\n",
       "      <th>EE_003</th>\n",
       "      <th>EE_004</th>\n",
       "      <th>EE_005</th>\n",
       "      <th>EE_006</th>\n",
       "      <th>EE_007</th>\n",
       "      <th>EE_008</th>\n",
       "      <th>EE_009</th>\n",
       "      <th>EF_000</th>\n",
       "      <th>EG_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370128</td>\n",
       "      <td>0</td>\n",
       "      <td>76698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031734</td>\n",
       "      <td>0</td>\n",
       "      <td>33058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101403</td>\n",
       "      <td>0</td>\n",
       "      <td>41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765778</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SPLIT  CLASS_POS  AA_000  AB_000      AC_000  AD_000  AE_000  AF_000  \\\n",
       "0  0.370128          0   76698     NaN  2130706438   280.0       0       0   \n",
       "1  0.031734          0   33058     NaN           0     NaN       0       0   \n",
       "2  0.101403          0   41040     NaN         228   100.0       0       0   \n",
       "3  0.765778          0      12     0.0          70    66.0       0      10   \n",
       "\n",
       "   AG_000  AG_001  ...   EE_002  EE_003  EE_004  EE_005  EE_006  EE_007  \\\n",
       "0       0       0  ...  1240520  493384  721044  469792  339156  157956   \n",
       "1       0       0  ...   421400  178064  293306  245416  133654   81140   \n",
       "2       0       0  ...   277378  159812  423992  409564  320746  158022   \n",
       "3       0       0  ...      240      46      58      44      10       0   \n",
       "\n",
       "   EE_008  EE_009  EF_000  EG_000  \n",
       "0   73224       0       0       0  \n",
       "1   97576    1500       0       0  \n",
       "2   95128     514       0       0  \n",
       "3       0       0       4      32  \n",
       "\n",
       "[4 rows x 172 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exasol.export_to_pandas(\"SELECT * FROM {schema!q}.TRAIN_PREPARED LIMIT 4\", {\"schema\": EXASOL_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and export the test data into an CSV file.\n",
    "\n",
    "To do so, we will introduce the Exasol database to directly export to the S3 bucket. For that it write permission for the S3 bucket.\n",
    "For that there are two options:\n",
    "\n",
    "* Provide credentials to the EXPORT command (if you decide for this solution, you have to edit the export statements below)\n",
    "* Leave connection empty and assign the permissions to the Exasol databases EC2 instance role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExaStatement session_id=1685765842211831808 stmt_idx=62>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "columns = exasol.export_to_pandas(\"SELECT * FROM {schema!q}.TRAIN_PREPARED LIMIT 1;\", {\"schema\": EXASOL_SCHEMA})\n",
    "column_names = list(columns)\n",
    "column_names.remove(\"SPLIT\") ## remove split column from select_list\n",
    "parameters = {\"all_columns_except_split\": column_names, \"schema\": EXASOL_SCHEMA, \"bucket\": bucket}\n",
    "exasol.execute(\"\"\"EXPORT (SELECT {all_columns_except_split!q} FROM {schema!q}.TRAIN_PREPARED WHERE SPLIT <= 0.8)\n",
    "                    INTO CSV AT 'https://{bucket!r}.s3.amazonaws.com'\n",
    "                    USER '' IDENTIFIED BY '' FILE 'train/train.csv';\"\"\", parameters)\n",
    "exasol.execute(\"\"\"EXPORT (SELECT {all_columns_except_split!q} FROM {schema!q}.TRAIN_PREPARED WHERE SPLIT > 0.8)\n",
    "                    INTO CSV AT 'https://{bucket!r}.s3.amazonaws.com'\n",
    "                    USER '' IDENTIFIED BY '' FILE 'validation/validation.csv';\"\"\", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exasol.execute(\"DROP TABLE {schema!q}.TRAIN_PREPARED;\",{\"schema\": EXASOL_SCHEMA});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model. The following cell will start an `ml.m4.xlarge` ec2 instance and run the training on it. It will read the training data from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-11 09:05:54 Starting - Starting the training job...\n",
      "2020-12-11 09:06:18 Starting - Launching requested ML instancesProfilerReport-1607677554: InProgress\n",
      "......\n",
      "2020-12-11 09:07:19 Starting - Preparing the instances for training......\n",
      "2020-12-11 09:08:19 Downloading - Downloading input data...\n",
      "2020-12-11 09:08:40 Training - Downloading the training image...\n",
      "2020-12-11 09:09:20 Training - Training image download completed. Training in progress...\u001B[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001B[0m\n",
      "\u001B[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001B[0m\n",
      "\u001B[34mReturning the value itself\u001B[0m\n",
      "\u001B[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001B[0m\n",
      "\u001B[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001B[0m\n",
      "\u001B[34mINFO:root:Determined delimiter of CSV input is ','\u001B[0m\n",
      "\u001B[34mINFO:root:Determined delimiter of CSV input is ','\u001B[0m\n",
      "\u001B[34mINFO:root:Determined delimiter of CSV input is ','\u001B[0m\n",
      "\u001B[34mINFO:root:Determined delimiter of CSV input is ','\u001B[0m\n",
      "\u001B[34mINFO:root:Single node training.\u001B[0m\n",
      "\u001B[34mINFO:root:Train matrix has 48162 rows\u001B[0m\n",
      "\u001B[34mINFO:root:Validation matrix has 11838 rows\u001B[0m\n",
      "\u001B[34m[0]#011train-error:0.00864#011validation-error:0.01191\u001B[0m\n",
      "\u001B[34m[1]#011train-error:0.00764#011validation-error:0.01064\u001B[0m\n",
      "\u001B[34m[2]#011train-error:0.00772#011validation-error:0.01056\u001B[0m\n",
      "\u001B[34m[3]#011train-error:0.00718#011validation-error:0.01031\u001B[0m\n",
      "\u001B[34m[4]#011train-error:0.00687#011validation-error:0.01056\u001B[0m\n",
      "\u001B[34m[5]#011train-error:0.00671#011validation-error:0.00997\u001B[0m\n",
      "\u001B[34m[6]#011train-error:0.00671#011validation-error:0.00946\u001B[0m\n",
      "\u001B[34m[7]#011train-error:0.00637#011validation-error:0.00963\u001B[0m\n",
      "\u001B[34m[8]#011train-error:0.00644#011validation-error:0.00946\u001B[0m\n",
      "\u001B[34m[9]#011train-error:0.00606#011validation-error:0.00929\u001B[0m\n",
      "\u001B[34m[10]#011train-error:0.00585#011validation-error:0.00946\u001B[0m\n",
      "\u001B[34m[11]#011train-error:0.00565#011validation-error:0.00938\u001B[0m\n",
      "\u001B[34m[12]#011train-error:0.00552#011validation-error:0.00946\u001B[0m\n",
      "\u001B[34m[13]#011train-error:0.00546#011validation-error:0.00912\u001B[0m\n",
      "\u001B[34m[14]#011train-error:0.00532#011validation-error:0.00912\u001B[0m\n",
      "\u001B[34m[15]#011train-error:0.00523#011validation-error:0.00938\u001B[0m\n",
      "\u001B[34m[16]#011train-error:0.00519#011validation-error:0.00904\u001B[0m\n",
      "\u001B[34m[17]#011train-error:0.00505#011validation-error:0.00904\u001B[0m\n",
      "\u001B[34m[18]#011train-error:0.00492#011validation-error:0.00895\u001B[0m\n",
      "\u001B[34m[19]#011train-error:0.00486#011validation-error:0.00887\u001B[0m\n",
      "\u001B[34m[20]#011train-error:0.00478#011validation-error:0.00862\u001B[0m\n",
      "\u001B[34m[21]#011train-error:0.00465#011validation-error:0.00895\u001B[0m\n",
      "\u001B[34m[22]#011train-error:0.00465#011validation-error:0.00853\u001B[0m\n",
      "\u001B[34m[23]#011train-error:0.00459#011validation-error:0.00904\u001B[0m\n",
      "\u001B[34m[24]#011train-error:0.00442#011validation-error:0.00870\u001B[0m\n",
      "\u001B[34m[25]#011train-error:0.00444#011validation-error:0.00887\u001B[0m\n",
      "\u001B[34m[26]#011train-error:0.00434#011validation-error:0.00912\u001B[0m\n",
      "\u001B[34m[27]#011train-error:0.00415#011validation-error:0.00878\u001B[0m\n",
      "\u001B[34m[28]#011train-error:0.00392#011validation-error:0.00862\u001B[0m\n",
      "\u001B[34m[29]#011train-error:0.00392#011validation-error:0.00836\u001B[0m\n",
      "\u001B[34m[30]#011train-error:0.00392#011validation-error:0.00836\u001B[0m\n",
      "\u001B[34m[31]#011train-error:0.00386#011validation-error:0.00811\u001B[0m\n",
      "\u001B[34m[32]#011train-error:0.00386#011validation-error:0.00828\u001B[0m\n",
      "\u001B[34m[33]#011train-error:0.00380#011validation-error:0.00828\u001B[0m\n",
      "\u001B[34m[34]#011train-error:0.00378#011validation-error:0.00819\u001B[0m\n",
      "\u001B[34m[35]#011train-error:0.00367#011validation-error:0.00819\u001B[0m\n",
      "\u001B[34m[36]#011train-error:0.00363#011validation-error:0.00819\u001B[0m\n",
      "\u001B[34m[37]#011train-error:0.00351#011validation-error:0.00836\u001B[0m\n",
      "\u001B[34m[38]#011train-error:0.00328#011validation-error:0.00819\u001B[0m\n",
      "\u001B[34m[39]#011train-error:0.00316#011validation-error:0.00786\u001B[0m\n",
      "\u001B[34m[40]#011train-error:0.00303#011validation-error:0.00794\u001B[0m\n",
      "\u001B[34m[41]#011train-error:0.00291#011validation-error:0.00777\u001B[0m\n",
      "\u001B[34m[42]#011train-error:0.00311#011validation-error:0.00786\u001B[0m\n",
      "\u001B[34m[43]#011train-error:0.00293#011validation-error:0.00811\u001B[0m\n",
      "\u001B[34m[44]#011train-error:0.00297#011validation-error:0.00786\u001B[0m\n",
      "\u001B[34m[45]#011train-error:0.00291#011validation-error:0.00802\u001B[0m\n",
      "\u001B[34m[46]#011train-error:0.00295#011validation-error:0.00811\u001B[0m\n",
      "\u001B[34m[47]#011train-error:0.00280#011validation-error:0.00811\u001B[0m\n",
      "\u001B[34m[48]#011train-error:0.00272#011validation-error:0.00786\u001B[0m\n",
      "\u001B[34m[49]#011train-error:0.00266#011validation-error:0.00769\u001B[0m\n",
      "\u001B[34m[50]#011train-error:0.00249#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[51]#011train-error:0.00247#011validation-error:0.00760\u001B[0m\n",
      "\u001B[34m[52]#011train-error:0.00241#011validation-error:0.00760\u001B[0m\n",
      "\u001B[34m[53]#011train-error:0.00237#011validation-error:0.00769\u001B[0m\n",
      "\u001B[34m[54]#011train-error:0.00231#011validation-error:0.00760\u001B[0m\n",
      "\u001B[34m[55]#011train-error:0.00226#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[56]#011train-error:0.00218#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[57]#011train-error:0.00210#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[58]#011train-error:0.00210#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[59]#011train-error:0.00206#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[60]#011train-error:0.00201#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[61]#011train-error:0.00197#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[62]#011train-error:0.00197#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[63]#011train-error:0.00193#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[64]#011train-error:0.00191#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[65]#011train-error:0.00189#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[66]#011train-error:0.00187#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[67]#011train-error:0.00183#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[68]#011train-error:0.00179#011validation-error:0.00726\u001B[0m\n",
      "\u001B[34m[69]#011train-error:0.00179#011validation-error:0.00726\u001B[0m\n",
      "\u001B[34m[70]#011train-error:0.00179#011validation-error:0.00760\u001B[0m\n",
      "\u001B[34m[71]#011train-error:0.00179#011validation-error:0.00760\u001B[0m\n",
      "\u001B[34m[72]#011train-error:0.00177#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[73]#011train-error:0.00177#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[74]#011train-error:0.00172#011validation-error:0.00726\u001B[0m\n",
      "\u001B[34m[75]#011train-error:0.00174#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[76]#011train-error:0.00170#011validation-error:0.00743\u001B[0m\n",
      "\u001B[34m[77]#011train-error:0.00172#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[78]#011train-error:0.00177#011validation-error:0.00726\u001B[0m\n",
      "\u001B[34m[79]#011train-error:0.00170#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[80]#011train-error:0.00158#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[81]#011train-error:0.00166#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[82]#011train-error:0.00164#011validation-error:0.00735\u001B[0m\n",
      "\u001B[34m[83]#011train-error:0.00158#011validation-error:0.00718\u001B[0m\n",
      "\u001B[34m[84]#011train-error:0.00154#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[85]#011train-error:0.00147#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[86]#011train-error:0.00147#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[87]#011train-error:0.00147#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[88]#011train-error:0.00143#011validation-error:0.00676\u001B[0m\n",
      "\u001B[34m[89]#011train-error:0.00147#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[90]#011train-error:0.00150#011validation-error:0.00701\u001B[0m\n",
      "\u001B[34m[91]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[92]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[93]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[94]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[95]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[96]#011train-error:0.00150#011validation-error:0.00710\u001B[0m\n",
      "\u001B[34m[97]#011train-error:0.00141#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[98]#011train-error:0.00135#011validation-error:0.00693\u001B[0m\n",
      "\u001B[34m[99]#011train-error:0.00131#011validation-error:0.00684\u001B[0m\n",
      "\n",
      "2020-12-11 09:10:21 Uploading - Uploading generated training model\n",
      "2020-12-11 09:10:21 Completed - Training job completed\n",
      "Training seconds: 114\n",
      "Billable seconds: 114\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = TrainingInput(s3_data='s3://{}/train'.format(bucket), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/validation/'.format(bucket), content_type='csv')\n",
    "\n",
    "container = image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-1' )\n",
    "xgb = Estimator(container,\n",
    "                role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m4.xlarge',\n",
    "                output_path='s3://{}/output'.format(bucket),\n",
    "                tags = tags\n",
    "               )\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an endpoint (ec2-instance that runs inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the newly created model, we will load the contents of the `TEST` table and run the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA_000</th>\n",
       "      <th>AB_000</th>\n",
       "      <th>AC_000</th>\n",
       "      <th>AD_000</th>\n",
       "      <th>AE_000</th>\n",
       "      <th>AF_000</th>\n",
       "      <th>AG_000</th>\n",
       "      <th>AG_001</th>\n",
       "      <th>AG_002</th>\n",
       "      <th>AG_003</th>\n",
       "      <th>...</th>\n",
       "      <th>EE_004</th>\n",
       "      <th>EE_005</th>\n",
       "      <th>EE_006</th>\n",
       "      <th>EE_007</th>\n",
       "      <th>EE_008</th>\n",
       "      <th>EE_009</th>\n",
       "      <th>EF_000</th>\n",
       "      <th>EG_000</th>\n",
       "      <th>CLASS_neg</th>\n",
       "      <th>CLASS_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>454</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2332.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>8476.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>38224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>337118.0</td>\n",
       "      <td>332806.0</td>\n",
       "      <td>225650.0</td>\n",
       "      <td>123556.0</td>\n",
       "      <td>131950.0</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA_000  AB_000  AC_000  AD_000  AE_000  AF_000  AG_000  AG_001  AG_002  \\\n",
       "3355     454     2.0     0.0    12.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8023   38224     NaN     0.0     NaN     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      AG_003  ...    EE_004    EE_005    EE_006    EE_007    EE_008  EE_009  \\\n",
       "3355     0.0  ...    2332.0    1912.0    1822.0    8476.0      90.0     0.0   \n",
       "8023     0.0  ...  337118.0  332806.0  225650.0  123556.0  131950.0  3338.0   \n",
       "\n",
       "      EF_000  EG_000  CLASS_neg  CLASS_pos  \n",
       "3355     0.0     0.0          1          0  \n",
       "8023     0.0     0.0          1          0  \n",
       "\n",
       "[2 rows x 172 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = exasol.export_to_pandas(\"SELECT * FROM {schema!q}.TEST\", {\"schema\": EXASOL_SCHEMA})\n",
    "test_data = pd.get_dummies(test_data)     # Convert categorical variables to sets of indicators\n",
    "test_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = CSVSerializer()\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.drop(['CLASS_pos', \"CLASS_neg\"], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions    0.0  1.0\n",
       "actuals                \n",
       "0            15623    2\n",
       "1              349   26"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data['CLASS_pos'], columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook leaves the endpoint running, so that you can use it for predictions.\n",
    "\n",
    "However, that causes costs. So if you don't need it anymore, don't forget to delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_predictor.delete_endpoint();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}