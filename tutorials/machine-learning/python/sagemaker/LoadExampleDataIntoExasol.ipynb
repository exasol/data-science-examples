{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Example Data Into the Exasol database\n",
    "\n",
    "In this Notebook we will load the \"Air pressure system failures in Scania trucks\" dataset into the exasol database using Python and Pyexasol. This Scania trucks dataset is a predictive maintenance scenario:\n",
    "\n",
    "> The dataset consists of data collected from heavy Scania trucks in everyday usage. The system in focus is the Air Pressure system (APS) which generates pressurized air that is utilized in various functions in a truck, such as braking and gear changes. The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS. The data consists of a subset of all available data, selected by experts.\n",
    "\n",
    "You can find further information [here](https://archive.ics.uci.edu/ml/datasets/IDA2016Challenge)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this we need:\n",
    "\n",
    "    - Connection information of the running Exasol database we want to load the data into.\n",
    "    - The url of the dataset we want to load (and knowledge of its structure).\n",
    "\n",
    "\n",
    "First we enter the connection details for the Exasol database we want to load the dataset into.\n",
    "Then we install pyexasol and import some dependencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXASOL_HOST = \"<database_host>\" # change, in case of Exasol Saas this can be a \"connection string\"\n",
    "EXASOL_PORT = \"8563\" # change if needed\n",
    "EXASOL_USER = \"sys\" # change if needed\n",
    "EXASOL_PASSWORD = \"<database_password>\" # change, in case of Exasol Saas this can be a personal access token\n",
    "EXASOL_SCHEMA = \"IDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyexasol\n",
    "\n",
    "import pyexasol\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we can use  the pyexasol connection to connect to our Exasol DB."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXASOL_CONNECTION = \"{host}:{port}\".format(host=EXASOL_HOST, port=EXASOL_PORT)\n",
    "exasol = pyexasol.connect(dsn=EXASOL_CONNECTION, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Example Data\n",
    "\n",
    "Now we download the dataset and write it to a zip-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00414/to_uci.zip\"\n",
    "\n",
    "resp = urlopen(DATA_URL)\n",
    "with open('to_uci.zip', 'wb') as f:  \n",
    "    f.write(resp.read())\n",
    "    \n",
    "print(\"data downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we read the contents of the downloaded zip-file into \"train_set\" and \"test_set\" variables respectively, using pandas to load the train- and test-tables from the csv files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE = \"to_uci/aps_failure_training_set.csv\"\n",
    "TEST_FILE = \"to_uci/aps_failure_test_set.csv\"\n",
    "\n",
    "# Data is preceded with a 20-line header (copyright & license)\n",
    "NUM_SKIP_ROWS = 20\n",
    "NA_VALUE = \"na\"\n",
    "\n",
    "with ZipFile('to_uci.zip') as z:\n",
    "    with z.open(TRAINING_FILE, \"r\") as f:\n",
    "        train_set = pd.read_csv(f, skiprows=NUM_SKIP_ROWS, na_values=NA_VALUE)\n",
    "    with z.open(TEST_FILE, \"r\") as f:\n",
    "        test_set = pd.read_csv(f, skiprows=NUM_SKIP_ROWS, na_values=NA_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Example Data\n",
    "\n",
    "In the last step we want to load the dataset into the exasol database. First we need to create a new schema \"EXASOL_SCHEMA\" using the pyexasol connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exasol.execute(query=\"CREATE SCHEMA IF NOT EXISTS {schema!i}\", query_params={\"schema\": EXASOL_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we need to create the \"EXASOL_SCHEMA.TRAIN\" and \"EXASOL_SCHEMA.TEST\" tables in the Exasol database with column names and types that match the tables from the data set. We do this by extracting the column names from the pandas table we created in the previous step. The column types for the Scania Trucks data set are VARCHAR(3) for the first column (\"class\"), and DECIMAL(18,2) for all other columns. We use the pyexasol connection we created previously to create these tables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names and types\n",
    "column_names = list(train_set.columns)\n",
    "column_types = [\"VARCHAR(3)\"] + [\"DECIMAL(18,2)\"] * (len(column_names) - 1)\n",
    "column_desc = [\" \".join(t) for t in zip(column_names, column_types)]\n",
    "\n",
    "params = {\"schema\": EXASOL_SCHEMA, \"column_names\": column_names, \"column_desc\": column_desc}\n",
    "\n",
    "# Create tables for data\n",
    "exasol.execute(query=\"CREATE OR REPLACE TABLE {schema!i}.TRAIN(\" + \", \".join(column_desc) + \")\", query_params=params)\n",
    "exasol.execute(query=\"CREATE OR REPLACE TABLE {schema!i}.TEST LIKE {schema!i}.TRAIN\", query_params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can use pyexasol's \"import_from_pandas\" functionality to import our pandas tables into our newly created Exasol tables using the pyexasol connection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import data into Exasol\n",
    "exasol.import_from_pandas(train_set, (EXASOL_SCHEMA, \"TRAIN\"))\n",
    "print(f\"Imported {exasol.last_statement().rowcount()} rows into TRAIN.\")\n",
    "exasol.import_from_pandas(test_set, (EXASOL_SCHEMA, \"TEST\"))\n",
    "print(f\"Imported {exasol.last_statement().rowcount()} rows into TEST.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now te Scania Trucks dataset should be available in the Exasol database in the Schema \"EXASOL_SCHEMA\" sorted into the \"TRAIN\" and the \"TEST\" tables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}