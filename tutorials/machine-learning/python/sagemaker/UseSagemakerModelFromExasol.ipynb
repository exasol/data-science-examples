{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use an AWS Sagemaker model from within Exasol\n",
    "\n",
    "In this notebook we will use an AWS Sagemaker model for predicitions from within Exasol queries.\n",
    "\n",
    "For that our exasol database needs permissions to use the Sagemaker inference Notebook.\n",
    "For that you can:\n",
    "\n",
    "* Provide credentials\n",
    "* Grant the permissions to the Role of the databases EC2 role.\n",
    "\n",
    "In this guide we will use the second approach.\n",
    "\n",
    "Grant the following permissions to your EC2 instance role:\n",
    "\n",
    "* `sts:AssumeRole` with a resource filter for the EC2 role itself.\n",
    "* `sagemaker:InvokeEndpoint` with a resource filter on your Sagemaker endpoint.\n",
    "\n",
    "In case you want to take the first approach, you can modify the UDF code below to use credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EXASOL_HOST = \"<database_host>\" # change\n",
    "EXASOL_PORT = \"8563\" # change if needed\n",
    "EXASOL_CONNECTION = \"{host}:{port}\".format(host=EXASOL_HOST, port=EXASOL_PORT)\n",
    "EXASOL_USER = \"sys\" # change if needed\n",
    "EXASOL_PASSWORD = \"<database_password>\" # change\n",
    "EXASOL_SCHEMA = \"IDA\" # change if needed\n",
    "EXASOL_CLUSTER_ROLE = \"<cluster_role>\" #change\n",
    "EXASOL_REGION = \"eu-central-1\" #change if needed\n",
    "ENDPOINT_NAME = \"<endpoint_name>\" #change"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyexasol\n",
    "\n",
    "import pyexasol\n",
    "import pandas as pd\n",
    "exasol = pyexasol.connect(dsn=EXASOL_CONNECTION, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install UDF\n",
    "\n",
    "In order to use the Sagemaker inference Endpoint from within the Exasol database, we will create a Python UDF that does API calls to the endpoint with the data from the query."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create schema\n",
    "exasol.execute(\"CREATE SCHEMA IF NOT EXISTS DATA_SCIENCE\")\n",
    "\n",
    "#create UDF\n",
    "exasol.execute(\"\"\"\n",
    "CREATE OR REPLACE PYTHON3 SET SCRIPT DATA_SCIENCE.PREDICT(...) EMITS(id DECIMAL(20,0), \"result\" BOOLEAN) AS\n",
    "def run(ctx):\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    f = open(\"/tmp/.config\", \"w\")\n",
    "    f.write(\n",
    "        \"[default]\\\\nregion = {region!r}\\\\nrole_arn = {role!r}\\\\ncredential_source = Ec2InstanceMetadata\")\n",
    "    f.close()\n",
    "    os.environ['AWS_CONFIG_FILE'] = '/tmp/.config'\n",
    "    while True:\n",
    "        df = ctx.get_dataframe(1000)\n",
    "        if df is None:\n",
    "            break\n",
    "        id_column = df[\"0\"]\n",
    "        df = df.drop(\"0\", 1)\n",
    "        client = boto3.client('sagemaker-runtime')\n",
    "        endpoint_name = \"{endpoint_name!r}\"\n",
    "        response = client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='text/csv',\n",
    "            Body=df.to_csv(header=False, index=False)\n",
    "        )\n",
    "        result_list = response['Body'].read().decode('ascii').split(\",\")\n",
    "        rounded_result = map(lambda x: bool(round(float(x))),result_list)\n",
    "        result = pd.DataFrame(list(rounded_result))\n",
    "        ctx.emit(pd.concat([id_column,result],axis=1))\n",
    "/\n",
    "\"\"\", {\n",
    "        \"region\": EXASOL_REGION,\n",
    "        \"role\": EXASOL_CLUSTER_ROLE,\n",
    "        \"endpoint_name\": ENDPOINT_NAME\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Query\n",
    "\n",
    "So let's run predictions on the test data table in Exasol."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_columns = exasol.export_to_pandas(\"SELECT * FROM \" + EXASOL_SCHEMA + \".TEST LIMIT 1;\")\n",
    "column_names = list(all_columns)\n",
    "column_names.remove(\"CLASS\")\n",
    "result = exasol.export_to_pandas(\"\"\"SELECT CLASS = 'pos' as \"expected\", \"result\" FROM  (\n",
    "                                     SELECT DATA_SCIENCE.PREDICT(ROWID, {columns_without_class!q}) FROM IDA.TEST t) r\n",
    "                                    JOIN IDA.TEST o ON r.ID = o.ROWID\"\"\", {\"columns_without_class\": column_names})\n",
    "pd.crosstab(index=result['expected'], columns=result[\"result\"], rownames=['actuals'], colnames=['predictions'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}